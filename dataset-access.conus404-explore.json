{"version":3,"kind":"Notebook","sha256":"f3b1fee214109a21816ef37a12b78aa563575b1ff972b31e4c86c009e9e4693e","slug":"dataset-access.conus404-explore","location":"/dataset_access/conus404_explore.ipynb","dependencies":[],"frontmatter":{"title":"Explore CONUS404 Dataset","content_includes_title":false,"github":"https://github.com/hytest-org/hytest","copyright":"2023","numbering":{"title":{"offset":2}},"source_url":"https://github.com/hytest-org/hytest/blob/main/dataset_access/conus404_explore.ipynb","edit_url":"https://github.com/hytest-org/hytest/edit/main/dataset_access/conus404_explore.ipynb","exports":[{"format":"ipynb","filename":"conus404_explore.ipynb","url":"/hytest//build/conus404_explore-474c970ce5218a60fa4d756693a58462.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This dataset was created by extracting specified variables from a collection of wrf2d output files, rechunking to better facilitate data extraction for a variety of use cases, and adding ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"BXwRZlpSGo"},{"type":"link","url":"https://cfconventions.org/","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"CF conventions","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"NehZ6XPoNF"}],"urlSource":"https://cfconventions.org/","key":"ULqgbdLbkk"},{"type":"text","value":" to allow easier analysis, visualization and data extraction using Xarray and Holoviz.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Y3qu2gG65a"}],"key":"dmRshHtlIZ"}],"key":"h38xrf1HOf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import os\nos.environ['USE_PYGEOS'] = '0'\n\nimport fsspec\nimport xarray as xr\nimport hvplot.xarray\nimport zarr\nimport pystac\nfrom packaging.version import Version\nimport metpy\nimport cartopy.crs as ccrs","key":"mEikehVNUc"},{"type":"outputs","id":"GepPD1PI06bnPfBaAUoTm","children":[],"key":"Jr5q2Q3anb"}],"key":"oJlTWikKP9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1) Select the Dataset from the WMA STAC Catalog","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AB7Ot3Y7Gi"}],"identifier":"id-1-select-the-dataset-from-the-wma-stac-catalog","label":"1) Select the Dataset from the WMA STAC Catalog","html_id":"id-1-select-the-dataset-from-the-wma-stac-catalog","implicit":true,"key":"LunVo6x7kO"}],"key":"OsMxf1wK0R"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def get_children(catalog, collection_id=None):\n    \"\"\"\n    This function retrieves a specified collection from a STAC catalog/collection and prints key metadata \n    for exploring/accessing the datasets contained within it.\n    If there is no collection ID provided, the collections in the top level of the catalog will be printed.\n    If a collection ID is provided, it will retrieve the collection with that ID from the input catalog/collection.\n    If the collection ID points to a dataset, it will print the assets available for the dataset.\n    If the collection ID points to another collection, it will list the child collections in the IDed collection.\n\n    Args:\n        catalog (pystac.Catalog | pystac.Collection): The STAC catalog/collection object.\n        collection_id (str): The ID of the collection or dataset to retrieve from catalog.\n    \n    Returns:\n        collection (pystac.Catalog | pystac.Collection): The collection object corresponding to the provided ID\n                                                         or the top-level catalog if no ID is provided.\n    \"\"\"\n    dataset = False\n    if collection_id:\n        collection = catalog.get_child(collection_id)\n        if collection.assets:\n            dataset = True\n            print(f\"{collection_id} is a dataset. Please review the assets below and select one to open.\")\n\n        else:\n            print(f\"{collection_id} is a collection. Please review the child items and select one to open in the next cell.\")\n    else:\n        collection = catalog\n    if dataset==True:\n        # List the assets\n        for asset in collection.assets:\n            print(f\"Asset ID: {asset}\")\n            print(f\"    Title: {collection.assets[asset].title}\")\n            print(f\"    Description: {collection.assets[asset].description}\")\n    else:\n        collections = list(collection.get_collections())\n        print(f\"Number of collections: {len(collections)}\")\n        print(\"Collections IDs:\")\n        for child_collection in collections:\n            id = child_collection.id\n            cite_as = \"Not available\"\n            for link in child_collection.links:\n                if link.rel == \"cite-as\":\n                    cite_as = link.target\n            print(f\"- {id}, Source: {cite_as}\")\n    return collection","key":"Uecxk3NQ6n"},{"type":"outputs","id":"JBCqAKUOurEHrtFIE8euV","children":[],"key":"NRzcMG5FFb"}],"key":"RDU2Co4Kx5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# url for the WMA STAC Catalog\ncatalog_url = \"https://api.water.usgs.gov/gdp/pygeoapi/stac/stac-collection/\"\n\n# use pystac to read the catalog\ncatalog = pystac.Catalog.from_file(catalog_url)\n\n# list the collections in the catalog\ncatalog = get_children(catalog)","key":"H46mLjj6Fr"},{"type":"outputs","id":"cK7r-PxhdNsHGOdLQGHiv","children":[],"key":"h6pFnQnvPT"}],"key":"Hx927SRrfM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# select a collection from the catalog, replace the collection ID with the one you want to use:\ncollection = get_children(catalog, collection_id=\"conus404\")","key":"UGtMCilZbY"},{"type":"outputs","id":"PbwnUmb0_ur6wRKPpU886","children":[],"key":"iQEw6gvQtH"}],"key":"n7n3tfpOEw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# select a collection from the catalog, replace the collection ID with the one you want to use:\ncollection = get_children(collection, collection_id=\"conus404_hourly\")","key":"WXdh3LoLTe"},{"type":"outputs","id":"EZHTM3Yljemjnu5MiIJsc","children":[],"key":"PaJNkmkszM"}],"key":"cQ6jYmMJGO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# replace with the asset ID you want to use:\nselected_asset_id = \"zarr-s3-osn\"\n\n# read the asset metadata\nasset = collection.assets[selected_asset_id]","key":"VJk5y8SslJ"},{"type":"outputs","id":"zbahE0DqtHMU1eyb-hsLQ","children":[],"key":"W4YE60bqUg"}],"key":"STFD055WSn"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2) Set Up AWS Credentials (Optional)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EaRaEBdPrI"}],"identifier":"id-2-set-up-aws-credentials-optional","label":"2) Set Up AWS Credentials (Optional)","html_id":"id-2-set-up-aws-credentials-optional","implicit":true,"key":"qe4hONoWZk"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook reads data from the OSN pod. The OSN pod is object store data on a high speed internet connection with free access from any computing environment. If you change this notebook to use one of the CONUS404 datasets stored on S3 (options ending in ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jr3VdHD8EE"},{"type":"inlineCode","value":"-cloud","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"F7KRvFQjTn"},{"type":"text","value":"), you will be pulling data from a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"h5ZyFhcBst"},{"type":"inlineCode","value":"requester-pays","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nKt7aAICfy"},{"type":"text","value":" S3 bucket. This means you have to set up your AWS credentials before you are able to load the data. Please note that reading the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"uCEIoNGMjU"},{"type":"inlineCode","value":"-cloud","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TE1lTkdfuu"},{"type":"text","value":" data from S3 may incur charges if you are reading data outside of AWSâ€™s ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kxVQhxcq85"},{"type":"inlineCode","value":"us-west-2","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Mg0JEhchHd"},{"type":"text","value":" region or running the notebook outside of the cloud altogether. If you would like to access one of the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NUmFvjEWPp"},{"type":"inlineCode","value":"-cloud","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DOdR3SdD6m"},{"type":"text","value":" options, uncomment and run the following code snippet to set up your AWS credentials. You can find more info about this AWS helper function ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"S77dxnIzno"},{"type":"link","url":"/environment-set-up/help-aws-credentials","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"iudJzMzduT"}],"urlSource":"../environment_set_up/Help_AWS_Credentials.ipynb","dataUrl":"/environment-set-up.help-aws-credentials.json","internal":true,"protocol":"file","key":"Ne6SWmPHIv"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DiTFqw7f90"}],"key":"GrpSXOgYM2"}],"key":"AhNUS5B4fI"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# uncomment the lines below to read in your AWS credentials if you want to access data from a requester-pays bucket (-cloud)\n# os.environ['AWS_PROFILE'] = 'default'\n# %run ../environment_set_up/Help_AWS_Credentials.ipynb","key":"g6E8HP3dBh"},{"type":"outputs","id":"KwtGKoANmMkaZ-MlIjBim","children":[],"key":"vyf8fEgdmF"}],"key":"s1gpPZf9FR"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"3) Parallelize with Dask (Optional, but recommended)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YnthYKAYiw"}],"identifier":"id-3-parallelize-with-dask-optional-but-recommended","label":"3) Parallelize with Dask (Optional, but recommended)","html_id":"id-3-parallelize-with-dask-optional-but-recommended","implicit":true,"key":"aw5uxhhzr0"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Some of the steps we will take are aware of parallel clustered compute environments\nusing ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"F4gvYywuW7"},{"type":"inlineCode","value":"dask","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"tuh5kqQmhX"},{"type":"text","value":". We will start a cluster so that future steps can take advantage\nof this ability.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"RNeT7qYe6A"}],"key":"QT7neYn1pz"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"This is an optional step, but speed ups data loading significantly, especially\nwhen accessing data from the cloud.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"aXAUpf5482"}],"key":"LewpGhWU0z"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"We have documentation on how to start a Dask Cluster in different computing environments ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"LR5KVltd4Q"},{"type":"link","url":"/environment-set-up/clusters","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"BytiIbJXAV"}],"urlSource":"../environment_set_up/clusters.md","dataUrl":"/environment-set-up.clusters.json","internal":true,"protocol":"file","key":"I2hsOqnQkc"},{"type":"text","value":".","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cAHWGkIcsr"}],"key":"WugZKv7gd6"}],"key":"yEyKO16imh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#%run ../environment_set_up/Start_Dask_Cluster_Nebari.ipynb\n## If this notebook is not being run on Nebari, replace the above \n## path name with a helper appropriate to your compute environment.  Examples:\n# %run ../environment_set_up/Start_Dask_Cluster_Denali.ipynb\n# %run ../environment_set_up/Start_Dask_Cluster_Tallgrass.ipynb\n# %run ../environment_set_up/Start_Dask_Cluster_Desktop.ipynb","key":"eIhmHITcOe"},{"type":"outputs","id":"iyeSAYKhsEtbKa3lggMM-","children":[],"key":"apo4RHa6O5"}],"key":"jLkuJSM4NG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4) Explore the dataset","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bwffUcln72"}],"identifier":"id-4-explore-the-dataset","label":"4) Explore the dataset","html_id":"id-4-explore-the-dataset","implicit":true,"key":"FjMzBOgK02"}],"key":"cehLJHR8d6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# read in the dataset and use metpy to parse the crs information on the dataset\nif Version(zarr.__version__) < Version(\"3.0.0\"):\n    ds = xr.open_dataset(\n        asset.href,\n        storage_options=asset.extra_fields['xarray:storage_options'],\n        **asset.extra_fields['xarray:open_kwargs']\n    )\nelse:\n    ds = xr.open_dataset(\n    asset.href,\n    storage_options=asset.extra_fields['xarray:storage_options'],\n    **asset.extra_fields['xarray:open_kwargs'],\n    zarr_format=2\n    )\nds = ds.metpy.parse_cf()\nds","key":"Dm8zkr5JCe"},{"type":"outputs","id":"P4GBuynrPSSR4ss1Xsh2p","children":[],"key":"tyiuvz4rq7"}],"key":"IeCajhxtiX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Examine the grid data structure for SNOW: \nds.SNOW","key":"wpgimX7cBh"},{"type":"outputs","id":"RnufW4xJUJSRWXi1kiQNE","children":[],"key":"LgaGDuSjid"}],"key":"VqNze1q6CY"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Looks like this dataset is organized in three coordinates (x, y, and time), and we have used the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yt3qSVvlcQ"},{"type":"inlineCode","value":"metpy","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WRtXqhhCgS"},{"type":"text","value":" package to pase the crs information into the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f74UKEjWSv"},{"type":"inlineCode","value":"metpy_crs","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nMMYH5DBvH"},{"type":"text","value":" variable:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hGwsUzMBH7"}],"key":"eEgQPtweeU"}],"key":"v0dkV4eYzC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"crs = ds['SNOW'].metpy.cartopy_crs\ncrs","key":"sApmlnEr6W"},{"type":"outputs","id":"iSyzRxY70K_BMBKlz7lsH","children":[],"key":"Hy1RzPPxor"}],"key":"y5a8hiDASy"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Example A: Load the entire spatial domain for a variable at a specific time step","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BERUZ7THGw"}],"identifier":"example-a-load-the-entire-spatial-domain-for-a-variable-at-a-specific-time-step","label":"Example A: Load the entire spatial domain for a variable at a specific time step","html_id":"example-a-load-the-entire-spatial-domain-for-a-variable-at-a-specific-time-step","implicit":true,"key":"q5UKaqExCD"}],"key":"GBB4gNzPUy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%time\nda = ds.SNOW_ACC_NC.sel(time='2009-12-24 00:00').load()\n### NOTE: the `load()` is dask-aware, so will operate in parallel if\n### a cluster has been started. ","key":"dh6oyo2eKO"},{"type":"outputs","id":"2_fKUmgHAokmNeqpu50Kd","children":[],"key":"iOS4jf00Lq"}],"key":"p7fyg9evco"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"da.hvplot.quadmesh(x='lon', y='lat', rasterize=True, geo=True, tiles='OSM', cmap='viridis').opts('Image', alpha=0.5)","key":"ayIIMwXWZV"},{"type":"outputs","id":"QhixcoN-NeJ70m5hTz0xh","children":[],"key":"j2TTZOyf6V"}],"key":"zTCFsSWM2O"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Example B: Load a time series for a variable at a specific grid cell for a specified time range","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RylPlh6e7S"}],"identifier":"example-b-load-a-time-series-for-a-variable-at-a-specific-grid-cell-for-a-specified-time-range","label":"Example B: Load a time series for a variable at a specific grid cell for a specified time range","html_id":"example-b-load-a-time-series-for-a-variable-at-a-specific-grid-cell-for-a-specified-time-range","implicit":true,"key":"IiNKpIaU5O"}],"key":"p09eRHxYYQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We will identify a point that we want to pull data for using lat/lon coordinates.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IIkFgCbUZW"}],"key":"VwX5E1lbmv"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The CONUS404 data is in a Lambert Conformal Conic projection, so we need to re-project/transform using the\nbuilt-in ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fIKtOhUVTH"},{"type":"inlineCode","value":"crs","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HB8psyEmh8"},{"type":"text","value":" we examined earlier.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IU2AEUueun"}],"key":"CgcaEC5Fin"}],"key":"DI6G5VhLcj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"lat,lon = 39.978322,-105.2772194    \nx, y = crs.transform_point(lon, lat, src_crs=ccrs.PlateCarree())   \nprint(x,y) # these vals are in LCC","key":"Z5Av9t4s6y"},{"type":"outputs","id":"SlGoSI5VoEoVeUQqKoicr","children":[],"key":"S7DYugTCvx"}],"key":"sJTUOW0BZK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%time\n# pull out a particulat time slice at the specified coordinates\nda = ds.PREC_ACC_NC.sel(x=x, y=y, method='nearest').sel(time=slice('2013-01-01 00:00','2013-12-31 00:00')).load()","key":"xsTg9M0rbO"},{"type":"outputs","id":"DY_EH9JrljM9-Yb6fIzSg","children":[],"key":"DVvtWztNKT"}],"key":"wFykyyP30O"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# plot your time series\nda.hvplot(x='time', grid=True)","key":"ytae8nEVAY"},{"type":"outputs","id":"bvVLqk_60Ai8TM3DDwUSY","children":[],"key":"XQXUHMUiDi"}],"key":"kmoGxZTzgp"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Stop cluster","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tYSqCvPPFM"}],"identifier":"stop-cluster","label":"Stop cluster","html_id":"stop-cluster","implicit":true,"key":"OfLznfXoYe"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Uncomment the line below if you started a dask cluster to shut it down.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"QBdC50sDzo"}],"key":"csxu445WxC"}],"key":"uEENqSUw6R"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#client.close(); cluster.shutdown()","key":"WT50rshuvu"},{"type":"outputs","id":"eqomsoMf8OzpBSBIWJ1UJ","children":[],"key":"gxlljJd1XL"}],"key":"Wze0sjd88q"}],"key":"iYnvC7otGN"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"CONUS404 Zarr Changelog","url":"/dataset-access/conus404-changelog","group":"Dataset Access"},"next":{"title":"Data Chunking Tutorial Overview","url":"/dataset-processing/tutorials/chunking/readme","group":"Zarr Creation"}}},"domain":"http://localhost:3005"}