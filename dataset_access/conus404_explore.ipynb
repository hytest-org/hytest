{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3edc9f-3c66-4e03-8c75-b147f15b2e50",
   "metadata": {},
   "source": [
    "# Explore CONUS404 Dataset\n",
    "This dataset was created by extracting specified variables from a collection of wrf2d output files, rechunking to better facilitate data extraction for a variety of use cases, and adding CF conventions to allow easier analysis, visualization and data extraction using Xarray and Holoviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b851f-3dd9-4b9f-988b-54c743a43bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import intake\n",
    "import metpy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57354df2-6786-4d1d-859e-1d5099cb85b9",
   "metadata": {},
   "source": [
    "## 1) Select the Dataset from HyTEST's Intake Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the hytest data intake catalog\n",
    "hytest_cat = intake.open_catalog(\"https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml\")\n",
    "list(hytest_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the conus404 sub-catalog\n",
    "cat = hytest_cat['conus404-catalog']\n",
    "list(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cdd988-4d56-49a5-85b4-d5d81c3db89d",
   "metadata": {},
   "source": [
    "**Select a dataset**: If you are unsure of which copy of a particular dataset to use (e.g. `conus404-hourly-?`), please review the [HyTEST JupyterBook](https://hytest-org.github.io/hytest/dataset_catalog/README.html#storage-locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c625-b5d7-4a17-ae2d-d7c2e8bc3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the dataset you want to read into your notebook and preview its metadata\n",
    "dataset = 'conus404-hourly-osn' \n",
    "cat[dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3711a89-7a6c-4cfd-b9d8-71f72104e97a",
   "metadata": {},
   "source": [
    "## 2) Set Up AWS Credentials (Optional)\n",
    "\n",
    "This notebook reads data from the OSN pod. The OSN pod is object store data on a high speed internet connection with free access from any computing environment. If you change this notebook to use one of the CONUS404 datasets stored on S3 (options ending in `-cloud`), you will be pulling data from a `requester-pays` S3 bucket. This means you have to set up your AWS credentials before you are able to load the data. Please note that reading the `-cloud` data from S3 may incur charges if you are reading data outside of AWS's `us-west-2` region or running the notebook outside of the cloud altogether. If you would like to access one of the `-cloud` options, uncomment and run the following code snippet to set up your AWS credentials. You can find more info about this AWS helper function [here](../environment_set_up/Help_AWS_Credentials.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771419fe-2f61-4bc1-b7dc-ddfacc6800ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the lines below to read in your AWS credentials if you want to access data from a requester-pays bucket (-cloud)\n",
    "# os.environ['AWS_PROFILE'] = 'default'\n",
    "# %run ../environment_set_up/Help_AWS_Credentials.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef85f6-01e4-4d84-9cce-0bf409b30637",
   "metadata": {},
   "source": [
    "## 3) Parallelize with Dask (Optional, but recommended)\n",
    "Some of the steps we will take are aware of parallel clustered compute environments\n",
    "using `dask`. We will start a cluster so that future steps can take advantage\n",
    "of this ability. \n",
    "\n",
    "This is an optional step, but speed ups data loading significantly, especially \n",
    "when accessing data from the cloud.\n",
    "\n",
    "We have documentation on how to start a Dask Cluster in different computing environments [here](../environment_set_up/clusters.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceea39d-78e2-4480-aaf3-0ead09b7e09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%run ../environment_set_up/Start_Dask_Cluster_Nebari.ipynb\n",
    "## If this notebook is not being run on Nebari/ESIP, replace the above \n",
    "## path name with a helper appropriate to your compute environment.  Examples:\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Denali.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Tallgrass.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Desktop.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_PangeoCHS.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59028b58-1a1a-4312-b8e1-ce11200eefef",
   "metadata": {},
   "source": [
    "## 4) Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2ce8a-6499-4413-861c-65d48f7af108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset and use metpy to parse the crs information on the dataset\n",
    "print(f\"Reading {dataset} metadata...\", end='')\n",
    "ds = cat[dataset].to_dask().metpy.parse_cf()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487472f-99fd-4bfa-98b5-742f8d935feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the grid data structure for SNOW: \n",
    "ds.SNOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235352e6-face-431f-932b-2f65e0e6beaf",
   "metadata": {},
   "source": [
    "Looks like this dataset is organized in three coordinates (x, y, and time), and we have used the `metpy` package to pase the crs information into the `metpy_crs` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d6030-19e3-4f61-800f-b0adda44bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ds['SNOW'].metpy.cartopy_crs\n",
    "crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e736ff3-b0e4-4452-af46-1afa462af185",
   "metadata": {},
   "source": [
    "## Example A: Load the entire spatial domain for a variable at a specific time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeca3c-0f2d-4e40-8139-523d544df4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds.SNOW_ACC_NC.sel(time='2009-12-24 00:00').load()\n",
    "### NOTE: the `load()` is dask-aware, so will operate in parallel if\n",
    "### a cluster has been started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46edc95-8904-4256-9729-7c09f03c51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.hvplot.quadmesh(x='lon', y='lat', rasterize=True, geo=True, tiles='OSM', cmap='viridis').opts('Image', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c71dae-3e8e-4293-b741-9c0992cc4c52",
   "metadata": {},
   "source": [
    "## Example B: Load a time series for a variable at a specific grid cell for a specified time range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd35652-608d-4eca-94d9-78cfd3591b38",
   "metadata": {},
   "source": [
    "We will identify a point that we want to pull data for using lat/lon coordinates.\n",
    "\n",
    "The CONUS404 data is in a Lambert Conformal Conic projection, so we need to re-project/transform using the\n",
    "built-in `crs` we examined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bae3e-54dc-46fd-8d52-c8bd48719285",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,lon = 39.978322,-105.2772194    \n",
    "x, y = crs.transform_point(lon, lat, src_crs=ccrs.PlateCarree())   \n",
    "print(x,y) # these vals are in LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cae05b-7a7b-4329-a707-bb8a7d137053",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# pull out a particulat time slice at the specified coordinates\n",
    "da = ds.PREC_ACC_NC.sel(x=x, y=y, method='nearest').sel(time=slice('2013-01-01 00:00','2013-12-31 00:00')).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e306cc-9c06-4079-96b1-12b1cf478ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot your time series\n",
    "da.hvplot(x='time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230a094-4dcd-4552-852e-be62cb29e15d",
   "metadata": {},
   "source": [
    "## Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aff08b-975d-47e1-ac51-6bb8e8b1adbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close(); cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
