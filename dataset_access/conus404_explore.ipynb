{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3edc9f-3c66-4e03-8c75-b147f15b2e50",
   "metadata": {},
   "source": [
    "# Explore CONUS404 Dataset\n",
    "This dataset was created by extracting specified variables from a collection of wrf2d output files, rechunking to better facilitate data extraction for a variety of use cases, and adding CF conventions to allow easier analysis, visualization and data extraction using Xarray and Holoviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b851f-3dd9-4b9f-988b-54c743a43bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import intake\n",
    "import metpy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57354df2-6786-4d1d-859e-1d5099cb85b9",
   "metadata": {},
   "source": [
    "## 1) Open dataset from Intake Catalog\n",
    "* Select `on-prem` dataset from /caldera if running on prem (Denali/Tallgrass)\n",
    "* Select `cloud`/`osn` data on S3 if running elsewhere.\n",
    "\n",
    "**NOTE This notebook reads data from OSN by default, which is free to access from any environment. If you change this notebook to use one of the CONUS404 datasets stored on S3 (options ending in `-cloud`), you will be pulling data from a `requester pays` bucket. This means you have to set up your AWS credentials, else we won't be able to load the data. Please note that reading the `-cloud` data from S3 may incur charges if you are reading data outside of the us-west-2 region or running the notebook outside of the cloud altogether. If you would like to access one of the `-cloud` options, add a code cell and run the following code snippet to set up your AWS credentials:\n",
    "```\n",
    "os.environ['AWS_PROFILE'] = 'default'\n",
    "%run ../environment_set_up/Help_AWS_Credentials.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the hytest data intake catalog\n",
    "hytest_cat = intake.open_catalog(\"https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml\")\n",
    "list(hytest_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the conus404 sub-catalog\n",
    "cat = hytest_cat['conus404-catalog']\n",
    "list(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c625-b5d7-4a17-ae2d-d7c2e8bc3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the dataset you want to read into your notebook and preview its metadata\n",
    "dataset = 'conus404-hourly-osn' \n",
    "cat[dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef85f6-01e4-4d84-9cce-0bf409b30637",
   "metadata": {},
   "source": [
    "## 2) Parallelize with Dask \n",
    "Some of the steps we will take are aware of parallel clustered compute environments\n",
    "using `dask`. We're going to start a cluster now so that future steps can take advantage\n",
    "of this ability. \n",
    "\n",
    "This is an optional step, but speed ups data loading significantly, especially \n",
    "when accessing data from the cloud.\n",
    "\n",
    "We have documentation on how to start a Dask Cluster in different computing environments [here](../environment_set_up/clusters.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceea39d-78e2-4480-aaf3-0ead09b7e09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../environment_set_up/Start_Dask_Cluster_Nebari.ipynb\n",
    "## If this notebook is not being run on Nebari/ESIP, replace the above \n",
    "## path name with a helper appropriate to your compute environment.  Examples:\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Denali.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Tallgrass.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Desktop.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_PangeoCHS.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59028b58-1a1a-4312-b8e1-ce11200eefef",
   "metadata": {},
   "source": [
    "## 3) Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2ce8a-6499-4413-861c-65d48f7af108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reading {dataset} metadata...\", end='')\n",
    "ds = cat[dataset].to_dask().metpy.parse_cf()\n",
    "print(\"done\")\n",
    "# Examine the grid data structure for SNOW: \n",
    "ds.SNOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235352e6-face-431f-932b-2f65e0e6beaf",
   "metadata": {},
   "source": [
    "Looks like this dataset is organized in three coordinates (x, y, and time).  There is a\n",
    "`metpy_crs` attached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d6030-19e3-4f61-800f-b0adda44bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ds['SNOW'].metpy.cartopy_crs\n",
    "crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e736ff3-b0e4-4452-af46-1afa462af185",
   "metadata": {},
   "source": [
    "## Example A: Load the entire spatial domain for a variable at a specific time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeca3c-0f2d-4e40-8139-523d544df4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds.SNOW_ACC_NC.sel(time='2009-12-24 00:00').load()\n",
    "### NOTE: the `load()` is dask-aware, so will operate in parallel if\n",
    "### a cluster has been started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46edc95-8904-4256-9729-7c09f03c51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.hvplot.quadmesh(x='lon', y='lat', rasterize=True, geo=True, tiles='OSM', cmap='viridis').opts('Image', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c71dae-3e8e-4293-b741-9c0992cc4c52",
   "metadata": {},
   "source": [
    "## Example B: Load a time series for a variable at a specific grid cell for a specified time range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd35652-608d-4eca-94d9-78cfd3591b38",
   "metadata": {},
   "source": [
    "**SIDE NOTE**\n",
    "To identify a point, we will start with its lat/lon coordinates.  But the\n",
    "data is in Lambert Conformal Conic... need to re-project/transform using the\n",
    "built-in `crs` we examined earlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bae3e-54dc-46fd-8d52-c8bd48719285",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,lon = 39.978322,-105.2772194    \n",
    "x, y = crs.transform_point(lon, lat, src_crs=ccrs.PlateCarree())   \n",
    "print(x,y) # these vals are in LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cae05b-7a7b-4329-a707-bb8a7d137053",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds.PREC_ACC_NC.sel(x=x, y=y, method='nearest').sel(time=slice('2013-01-01 00:00','2013-12-31 00:00')).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e306cc-9c06-4079-96b1-12b1cf478ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.hvplot(x='time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230a094-4dcd-4552-852e-be62cb29e15d",
   "metadata": {},
   "source": [
    "## Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aff08b-975d-47e1-ac51-6bb8e8b1adbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close(); cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-users-pangeo",
   "language": "python",
   "name": "conda-env-users-users-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
