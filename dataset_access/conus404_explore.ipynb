{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3edc9f-3c66-4e03-8c75-b147f15b2e50",
   "metadata": {},
   "source": [
    "# Explore Cloud-Optimized CONUS404 Dataset\n",
    "This dataset was created by extracting specified variables from a collection of wrf2d output files, rechunking to better facilitate data extraction for a variety of use cases, and adding CF conventions to allow easier analysis, visualization and data extraction using Xarray and Holoviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b851f-3dd9-4b9f-988b-54c743a43bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import intake\n",
    "import metpy\n",
    "import cartopy.crs as ccrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57354df2-6786-4d1d-859e-1d5099cb85b9",
   "metadata": {},
   "source": [
    "## Open Dataset\n",
    "\n",
    "### 1) intake\n",
    "For this demonstration notebook, we will open a cloud-native dataset. The details\n",
    "of its access are stored in an `intake` catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c625-b5d7-4a17-ae2d-d7c2e8bc3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog(\n",
    "    r\"https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml\"\n",
    ")\n",
    "## NOTE: we happen to know this dataset's handle/name.\n",
    "dataset = 'conus404-hourly-cloud' \n",
    "## If you did not know this name, you could list the datasets in the catalog with\n",
    "## the command `list(cat)`\n",
    "\n",
    "## But since we do know the name, let's see its metadata\n",
    "cat[dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287be86e-3f1b-477d-ad4a-36f7776153db",
   "metadata": {},
   "source": [
    "**NOTE** This particular dataset has the `requester_pays` option set to true.  This means\n",
    "we have to set up our AWS credentials, else we won't be able to load the data from S3 \n",
    "object storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a868a0-71ff-4bab-8525-f9f46d1d7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_PROFILE'] = 'default'\n",
    "%run ../environment_set_up/Help_AWS_Credentials.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef85f6-01e4-4d84-9cce-0bf409b30637",
   "metadata": {},
   "source": [
    "### 2) Start parallel cluster\n",
    "Some of the steps we will take are aware of parallel clustered compute environments\n",
    "using `dask`. We're going to start a cluster now so that future steps can take advantage\n",
    "of this ability. \n",
    "\n",
    "This is an optional step, but can speed up data loading significantly, especially \n",
    "when accessing data from the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceea39d-78e2-4480-aaf3-0ead09b7e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../environment_set_up/Start_Dask_Cluster_Nebari.ipynb\n",
    "## If this notebook is not being run on Nebari/ESIP, replace the above \n",
    "## path name with a helper appropriate to your compute environment.  Examples:\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Denali.ipynb\n",
    "# %run ../environment_set_up/Start_Dask_Cluster_Tallgrass.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59028b58-1a1a-4312-b8e1-ce11200eefef",
   "metadata": {},
   "source": [
    "### 3) Explore and verify the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2ce8a-6499-4413-861c-65d48f7af108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reading {dataset} metadata...\", end='')\n",
    "ds = cat[dataset].to_dask().metpy.parse_cf()\n",
    "print(\"done\")\n",
    "# Examine the grid data structure for SNOW: \n",
    "ds.SNOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235352e6-face-431f-932b-2f65e0e6beaf",
   "metadata": {},
   "source": [
    "Looks like this dataset is organized in three coordinates (x, y, and time).  There is a\n",
    "`metpy_crs` attached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d6030-19e3-4f61-800f-b0adda44bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ds['SNOW'].metpy.cartopy_crs\n",
    "crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e736ff3-b0e4-4452-af46-1afa462af185",
   "metadata": {},
   "source": [
    "## Use Case 1:  Load the full domain at a specific time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeca3c-0f2d-4e40-8139-523d544df4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds.SNOW.sel(time='2014-03-01 00:00').load()\n",
    "### NOTE: the `load()` is dask-aware, so will operate in parallel if\n",
    "### a cluster has been started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46edc95-8904-4256-9729-7c09f03c51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.hvplot.quadmesh(\n",
    "    x='lon', \n",
    "    y='lat', \n",
    "    rasterize=True, \n",
    "    geo=True, \n",
    "    tiles='OSM', \n",
    "    alpha=0.66, \n",
    "    cmap='plasma'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c71dae-3e8e-4293-b741-9c0992cc4c52",
   "metadata": {},
   "source": [
    "## Use case 2: Load the full time series at a specific grid cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0ea7f-5b93-493f-b1db-39010e601b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.PREC_ACC_NC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd35652-608d-4eca-94d9-78cfd3591b38",
   "metadata": {},
   "source": [
    "**SIDE NOTE**\n",
    "To identify a point, we will start with its lat/lon coordinates.  But the\n",
    "data is in Lambert Conformal Conic... need to re-project/transform using the\n",
    "built-in `crs` we examined earlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bae3e-54dc-46fd-8d52-c8bd48719285",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,lon = 39.978322,-105.2772194    \n",
    "x, y = crs.transform_point(lon, lat, src_crs=ccrs.PlateCarree())   \n",
    "print(x,y) # these vals are in LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cae05b-7a7b-4329-a707-bb8a7d137053",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds.PREC_ACC_NC.sel(x=x, y=y, method='nearest').sel(time=slice('2013-01-01 00:00','2013-12-31 00:00')).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e306cc-9c06-4079-96b1-12b1cf478ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.hvplot(x='time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230a094-4dcd-4552-852e-be62cb29e15d",
   "metadata": {},
   "source": [
    "## Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aff08b-975d-47e1-ac51-6bb8e8b1adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close(); cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22ff23-1822-4b97-a7d0-3721caf33d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-users-pangeo",
   "language": "python",
   "name": "conda-env-users-users-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "85ce4eb777a47250062e69db63a13ea88790b42e9bccd9f9c9a4eb5ac7d53107"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
