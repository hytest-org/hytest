{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a filesystem to access the data files\n",
    "fs = fsspec.filesystem('s3', endpoint_url='https://usgs.osn.mghpcc.org/', anon=True)\n",
    "\n",
    "# list the directories and files in the top level directory for this data release\n",
    "base_url = \"s3://hytest/wrf_hydro_nhdplusv2_conus404ba_1980-2022/\"\n",
    "fs.ls(base_url)\n",
    "# note: the url can be appended with additional sub-directories to drill down and explore the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0708803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's choose a particular set of files to look at\n",
    "# we will make a list of all the CHANOBS - Level_Pool model outputs for one water year\n",
    "file_dir = os.path.join(base_url, 'model_outputs_netcdf/CHANOBS/Level_Pool/WY2001')\n",
    "nc_urls = fs.ls(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's open and view the first of these files to see what it looks like\n",
    "ds = xr.open_dataset(fs.open(nc_urls[0]))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ee5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's open several time steps of this hourly data all at once so we can plot a time series of the data\n",
    "# First, choose how many files you want to open. It takes ~2 minutes for a month, ~25 minutes for a full water year\n",
    "# We will open the first month of data (31 days * 24 hours = 744 files)\n",
    "num_files_to_open = 744\n",
    "\n",
    "# open up each time step's file and append it to a list of datasets\n",
    "datasets = []\n",
    "for url in nc_urls[:num_files_to_open]:\n",
    "    ds = xr.open_dataset(fs.open(url, mode=\"rb\"), engine=\"h5netcdf\") \n",
    "    datasets.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a143ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all time steps' datasets into a single xarray dataset\n",
    "combined_ds = xr.combine_by_coords(datasets, coords='minimal', compat='override', combine_attrs='override')\n",
    "combined_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ba0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot a streamflow time series at a particular location\n",
    "# choose the feature_id you want to plot:\n",
    "feature_id = 15448784\n",
    "combined_ds.sel(feature_id=feature_id).streamflow.hvplot(x='time', grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9808b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
