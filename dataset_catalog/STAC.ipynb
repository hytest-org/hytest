{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8010c4a9",
   "metadata": {},
   "source": [
    "# Water Mission Area STAC Catalog\n",
    "\n",
    "The [USGS Water Resources Mission Area (WMA)](http://water.usgs.gov/) has created a [STAC Catalog](https://stacspec.org/) to help users find and access data related to our water modeling projects. STAC Catalogs provide a mechanism to expose spatiotemporal datasets using a machine-readable format, allowing users to discover and access datasets in a standardized way. The WMA Catalog hosts a variety of datasets related to hydro-terrestrial modeling. The scope of the WMA STAC Catalog datasets may include:\n",
    "- common hydrologic model inputs such as climate or other forcing datasets\n",
    "- hydrologic model outputs\n",
    "- observational datasets related to hydrology and/or water budgets\n",
    "\n",
    "We have exposed our STAC Catalog through a [pygeoapi](https://pygeoapi.io/) endpoint that is compliant with the [OGC API suite of standards](https://ogcapi.ogc.org/). This endpoint allows both API access, as well as a user interface for browsing our data assets.\n",
    "\n",
    "This STAC Catalog is part of a [modernized replacement for the legacy Geo Data Portal](https://waterdata.usgs.gov/blog/gdp-moving/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11170d29",
   "metadata": {},
   "source": [
    "## Finding the data you need and reading it into your workflow\n",
    "\n",
    "You have two ways to discover the data assets in the WMA STAC Catalog:\n",
    "1. Using the [pygeoapi user interface](https://api.water.usgs.gov/gdp/pygeoapi/stac/stac-collection) to browse our datasets through a user interface.\n",
    "2. Reading the pygeoapi API endpoint into a workflow using a library designed for reading STAC catalogs, such as [PySTAC](https://pystac.readthedocs.io/en/stable/).\n",
    "\n",
    "We will describe/demonstrate both methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import the packages we will need\n",
    "import pystac\n",
    "import xarray as xr\n",
    "import zarr\n",
    "from packaging.version import Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c8b0c",
   "metadata": {},
   "source": [
    "### Option 1: Find and access a dataset using the PyGEOAPI or Radiant Earth user interface\n",
    "Step 1: Explore the catalog through either our [pygeoapi user interface](https://api.water.usgs.gov/gdp/pygeoapi/stac/stac-collection) or the [Radiant Earth STAC Browser](https://radiantearth.github.io/stac-browser/#/external/api.water.usgs.gov/gdp/pygeoapi/stac/stac-collection?.language=en) and find the dataset you want to use.\n",
    "  - This catalog contains both *datasets* and *collections of datasets* in the top level of the catalog. Therefore, some assets that you click may open up directly to a dataset explore page (with a map viewer and metadata about the dataset), while others will open up to another catalog listing. As you drill down through the collections, you will eventually land on a dataset explore page.\n",
    "  - You can learn more about each dataset at its source publication point, which is linked in the `cite-as` property displayed on each dataset page (if available).\n",
    "  - Click through the catalog until you find a dataset that you want to use. For this example, we will use the **gridMET** dataset.\n",
    "\n",
    "Step 2: Identify which asset you want to use to access the dataset you've chosen.\n",
    "  - Review the `Title` and `Description` of each asset listed in the **Assets** section. Each asset is a different copy of the dataset that may be stored in a different format or location.\n",
    "  - Typically, we recommend using the asset with the title \"Free access to zarr via S3 API\".\n",
    "  - Copy the `URL`, `Open Keywords`, and `Storage Options` for the asset you have chosen, and store them as python variables, demonstrated below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "zarr_url = 's3://hytest/conus404/conus404_hourly.zarr/'\n",
    "\n",
    "# Open Keywords\n",
    "# note that you will need to capitalize the True or False in \"consolidated\" - these keys are stored as lowercase boolens in the STAC catalog json\n",
    "# but should be capitalized for python\n",
    "open_keywords = {\n",
    "  \"chunks\": {},\n",
    "  \"consolidated\": True,\n",
    "  \"engine\": \"zarr\"\n",
    "}\n",
    "\n",
    "# Storage Options\n",
    "# note that you will need to capitalize the True or False in \"anon\" - these keys are stored as lowercase boolens in the STAC catalog json\n",
    "# but should be capitalized for python\n",
    "storage_options = {\n",
    "  \"anon\": True,\n",
    "  \"client_kwargs\": {\n",
    "    \"endpoint_url\": \"https://usgs.osn.mghpcc.org/\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c072d89",
   "metadata": {},
   "source": [
    "#### Open the dataset using xarray\n",
    "Now we will open and view the dataset using xarray.\n",
    " \n",
    "Please note that there are two major zarr format specifications: 2 and 3. If you are using the python package `zarr>=3.0.0`, you must specify the format of the zarr store you are trying to open in the `xarray.open_dataset` function. If you are using `zarr<3.0.0`, you do not need to specify the format, as it will default to version 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Version(zarr.__version__) < Version(\"3.0.0\"):\n",
    "    ds = xr.open_dataset(\n",
    "        zarr_url,\n",
    "        storage_options=storage_options,\n",
    "        **open_keywords\n",
    "    )\n",
    "else:\n",
    "    ds = xr.open_dataset(\n",
    "    zarr_url,\n",
    "    storage_options=storage_options,\n",
    "    **open_keywords,\n",
    "    zarr_format=2\n",
    "    )\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6164e8",
   "metadata": {},
   "source": [
    "### Option 2: Find and access a dataset using the PySTAC python library\n",
    "Before we begin, we will define a helper function that can be used to drill down through the STAC Catalog and extract key metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(catalog, collection_id=None):\n",
    "    \"\"\"\n",
    "    This function retrieves a specified collection from a STAC catalog/collection and prints key metadata \n",
    "    for exploring/accessing the datasets contained within it.\n",
    "    If there is no collection ID provided, the collections in the top level of the catalog will be printed.\n",
    "    If a collection ID is provided, it will retrieve the collection with that ID from the input catalog/collection.\n",
    "    If the collection ID points to a dataset, it will print the assets available for the dataset.\n",
    "    If the collection ID points to another collection, it will list the child collections in the IDed collection.\n",
    "\n",
    "    Args:\n",
    "        catalog (pystac.Catalog | pystac.Collection): The STAC catalog/collection object.\n",
    "        collection_id (str): The ID of the collection or dataset to retrieve from catalog.\n",
    "    \n",
    "    Returns:\n",
    "        collection (pystac.Catalog | pystac.Collection): The collection object corresponding to the provided ID\n",
    "                                                         or the top-level catalog if no ID is provided.\n",
    "    \"\"\"\n",
    "    dataset = False\n",
    "    if collection_id:\n",
    "        collection = catalog.get_child(collection_id)\n",
    "        if collection.assets:\n",
    "            dataset = True\n",
    "            print(f\"{collection_id} is a dataset. Please review the assets below and select one to open.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"{collection_id} is a collection. Please review the child items and select one to open in the next cell.\")\n",
    "    else:\n",
    "        collection = catalog\n",
    "    if dataset==True:\n",
    "        # List the assets\n",
    "        for asset in collection.assets:\n",
    "            print(f\"Asset ID: {asset}\")\n",
    "            print(f\"    Title: {collection.assets[asset].title}\")\n",
    "            print(f\"    Description: {collection.assets[asset].description}\")\n",
    "    else:\n",
    "        collections = list(collection.get_collections())\n",
    "        print(f\"Number of collections: {len(collections)}\")\n",
    "        print(\"Collections IDs:\")\n",
    "        for child_collection in collections:\n",
    "            id = child_collection.id\n",
    "            cite_as = \"Not available\"\n",
    "            for link in child_collection.links:\n",
    "                if link.rel == \"cite-as\":\n",
    "                    cite_as = link.target\n",
    "            print(f\"- {id}, Source: {cite_as}\")\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3ff15",
   "metadata": {},
   "source": [
    "Step 1: Explore the catalog using the [PySTAC](https://pystac.readthedocs.io/en/stable/) library and find the dataset you want to use.\n",
    "  - The following code will read the WMA STAC Catalog and print the items in the top level of the catalog.\n",
    "  - This catalog contains both *datasets* and *collections of datasets* in the top level of the catalog. Therefore, some collections may point to a dataset endpoint, while others will point to another collection of several datasets. As you drill down through the collections, you will eventually land on a dataset.\n",
    "  - You can learn more about each dataset at its source publication point, which the helper function defined above prints out (if available).\n",
    "  - Identify a dataset that you want to use. For this example, we will use the **gridMET** dataset.\n",
    "\n",
    "*Note: We are working on enabling stac-search to our pygeoapi endpoint, which will allow you to search for datasets using keywords and other metadata which will help facilitate this exploration process.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50132dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for the WMA STAC Catalog\n",
    "catalog_url = \"https://api.water.usgs.gov/gdp/pygeoapi/stac/stac-collection/\"\n",
    "\n",
    "# use pystac to read the catalog\n",
    "catalog = pystac.Catalog.from_file(catalog_url)\n",
    "\n",
    "# list the collections in the catalog\n",
    "catalog = get_children(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a collection from the catalog, replace the collection ID with the one you want to use:\n",
    "collection = get_children(catalog, collection_id=\"conus404\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd641dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the above was a collection, uncomment the line below and enter the collection ID \n",
    "# you want to use from the parent collection you selected:\n",
    "collection = get_children(collection, collection_id=\"conus404_hourly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89854302",
   "metadata": {},
   "source": [
    "Step 2: Identify which asset you want to use to access the dataset you've chosen.\n",
    "  - Review the `Title` and `Description` of each asset printed above. Each asset is a different copy of the dataset that may be stored in a different format or location.\n",
    "  - Typically, we recommend people use the `zarr-s3-osn` asset unless they have a reason to use a different asset.\n",
    "  - Copy the Asset ID for the asset you have chosen, and paste in the code below to read the asset metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da52bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with the asset ID you want to use:\n",
    "selected_asset_id = \"zarr-s3-osn\"\n",
    "\n",
    "# read the asset metadata\n",
    "asset = collection.assets[selected_asset_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10382a6e",
   "metadata": {},
   "source": [
    "#### Open the dataset using xarray\n",
    "Now we will open and view the dataset using xarray.\n",
    "\n",
    "Please note that there are two major zarr format specifications: 2 and 3. If you are using the python package `zarr>=3.0.0`, you must specify the format of the zarr store you are trying to open in the `xarray.open_dataset` function. If you are using `zarr<3.0.0`, you do not need to specify the format, as it will default to version 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Version(zarr.__version__) < Version(\"3.0.0\"):\n",
    "    ds = xr.open_dataset(\n",
    "        asset.href,\n",
    "        storage_options=asset.extra_fields['xarray:storage_options'],\n",
    "        **asset.extra_fields['xarray:open_kwargs']\n",
    "    )\n",
    "else:\n",
    "    ds = xr.open_dataset(\n",
    "    asset.href,\n",
    "    storage_options=asset.extra_fields['xarray:storage_options'],\n",
    "    **asset.extra_fields['xarray:open_kwargs'],\n",
    "    zarr_format=2\n",
    "    )\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62227d",
   "metadata": {},
   "source": [
    "You can use whichever of the two methods described above to find and access datasets from our STAC Catalog. Now that you have the dataset open in xarray, you can build on the workflow to visualize, analyze, or do any other data processing you might need to do. You don't need to download your own copy of the dataset - you can perform your analysis directly on the dataset from the source we provide. If your workflow exceeds your computer's memory, you can use the `dask` library to parallelize your analysis and take advantage of HPC or scalable cloud computing resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c7006",
   "metadata": {},
   "source": [
    "## Reporting Issues with the Catalog\n",
    "If you find any issues with our STAC catalog or the datasets it contains, please reach out to us in one of the following ways:\n",
    "- If you have a `code.usgs.gov` account, you can [open an issue](https://code.usgs.gov/wma/nhgf/geo-data-portal/gdp_data_processing/-/issues/new)\n",
    "- E-mail us at `mdmf@usgs.gov`\n",
    "\n",
    "We will do our best to address any issues you find in a timely manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616fa5d6",
   "metadata": {},
   "source": [
    "## Contributing to the Catalog\n",
    "We are very interested in expanding the datasets available in our STAC Catalog to include more datasets that are relevant to water modeling. If you have a dataset that you think should be included, we would love to hear from you! We are particularly interested in datasets that are very large or difficult to access. Please [open an issue](https://code.usgs.gov/wma/nhgf/stac/-/issues/new?description_template=addition_inquiry) if you think you have a dataset that should be included in the catalog and tell us a bit about the dataset, who is using it, and why you would like to add it to our STAC Catalog."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
