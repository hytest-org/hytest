{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc211372-d1a5-478a-8f2e-22c75052b851",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HyTEST Tutorial: Cache NWIS data to Zarr\n",
    "\n",
    "#### Rich Signell, last updated June 2022\n",
    "\n",
    "* Tutorial uses pyriver geohydro package extracts streamflow from NWIS\n",
    "* Here we query all the gages identified in the National Water Model 2.1 over the simulation period and store to zarr for faster access \n",
    "\n",
    "[Rendered notebook with output](https://nbviewer.org/gist/3d38160704a7d8f606f99a3ee07680ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b4646-fe42-4708-a391-4c4f979b480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600fb4d-56ff-4a46-bb43-f7cac3e7f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021b65c-d237-4a1c-8127-38685a1a187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import hvplot.xarray\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from zarr.convenience import consolidate_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab4b31-33cd-4c41-ae92-817a0c296c7c",
   "metadata": {},
   "source": [
    "### Import Modeled Data from URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e727e-1d92-4b40-9fd5-ba0ef8498e1c",
   "metadata": {},
   "source": [
    "Load model dataset that contains stations and time range of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ffea2-3b3b-43c2-8f4f-bed85e895c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2 = fsspec.filesystem('s3', requester_pays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df576b7-582d-49f7-bd6e-3d6eee3464c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2.ls('s3://nhgf-development/nwm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9b0dd-3967-4382-ba88-f658ebd5e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 's3://nhgf-development/nwm/chanobs.zarr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba52be-9e93-40a2-b5ca-78dc61e17ad4",
   "metadata": {},
   "source": [
    "#### create xarray dataset of modeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981727a-b8e8-4aa9-8751-bb8d2049db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_chanobs = xr.open_dataset(fs2.get_mapper(url), engine='zarr', \n",
    "                             backend_kwargs={'consolidated':False}, chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e6ac7-0497-4db2-8ea0-317ebe279b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chanobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de12ef-6bf6-405d-9340-c8c9054b68b1",
   "metadata": {},
   "source": [
    "#### About modeled data\n",
    "The dataset called \"ds_chanobs\" is the \"channel observations\" streamflow modeled output from the National Water Model v2.1\n",
    "\n",
    "This xarray dataset contains hourly streamflow predictions at 7994 streamflow stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb356c5-8593-427d-8829-f31f4035474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chanobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68a37d-9f43-4405-bbc7-7a404c74ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine what USGS station ids are in the modeled output.\n",
    "gage_ids_str = [gage_id.astype('str').lstrip() for gage_id in ds_chanobs['gage_id'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae24da7-257d-4f5a-bbe2-9f7d04710b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## what the gage IDs look like:\n",
    "gage_ids_str[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005feed4-a9d8-4be5-9444-2aea271c312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the start and end of the modeled timeseries\n",
    "start = ds_chanobs.time[0].values\n",
    "stop = ds_chanobs.time[-1].values\n",
    "print(start,stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461593ba-cb2b-4c82-a14f-73d72ae6a068",
   "metadata": {},
   "source": [
    "#### Extract obs data using hyriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec05b0-7709-41b6-9acf-9757fcfc5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pygeohydro\n",
    "from pygeohydro import NWIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585b6dc-b667-4f25-a63b-55347d65b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis = NWIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62f660-3959-4c92-bff9-f9f951ed0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the start and stop dates above from the modeled data to extract observational data from NWIS for the same time period\n",
    "dates = (start,stop)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f1b33-562f-4b1e-93b7-04857e817066",
   "metadata": {},
   "source": [
    "If we request only one station, we get a time series with just good data (doesn't span the time window).  So we request two stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a372ef-47be-4b34-ae4c-018d47ffe584",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_obs = nwis.get_streamflow(gage_ids_str[:2], dates, to_xarray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99914be9-306f-430a-aeb0-549c7a74a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine xarray dataset of pulled information for each USGS station ID and associated streamflow in cfs\n",
    "ds_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238b26b-1d43-455d-9fd1-f8e32976d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables\n",
    "ds_obs = ds_obs.rename_dims({'station_id':'gage_id'}).rename({'station_id':'gage_id','discharge':'streamflow'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b2773-637e-4dd1-8850-31a74875b5ed",
   "metadata": {},
   "source": [
    "Define time base for interpolatation of subsequent NWIS data requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d52f3-9149-4317-b411-abf2f9e248b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_base = ds_obs.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ff33b-db72-493d-89e1-713ad6763b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0607326-2fe0-41db-8a79-3595a73a9a0a",
   "metadata": {},
   "source": [
    "### Identify directory to store this saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474f64d-f65e-48b5-bd83-f5d48c9e909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache data in this directory [change to your directory]:\n",
    "# dir_scratch = Path('/caldera/projects/usgs/hazards/cmgp/woodshole/rsignell/conus404/zarr')\n",
    "# file_chanobs = dir_scratch / 'nwis_chanobs2.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77147619-5b08-4f28-909a-243914a4361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit this to your directory where you wish to save NWIS streamflow information\n",
    "dir_scratch = Path('/caldera/projects/usgs/water/wbbp/')\n",
    "file_chanobs = dir_scratch / 'nwis_chanobs2.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdd5dc-ab34-4d14-b61d-30cfc88e16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_chanobs.is_dir():\n",
    "    fs.rm(str(file_chanobs),recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2138ba-acfb-4910-b5f2-83a39c886de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gage_ids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cc018-443a-484a-9b22-60e428078aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dataset = ds_obs.drop_vars(drop_vars)\n",
    "source_dataset = ds_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4092ad2-0f40-4ca2-8f3b-2f3afb422aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (source_dataset.chunk().\n",
    "            pipe(xr.zeros_like).\n",
    "            isel(gage_id=0, drop=True).\n",
    "            expand_dims(gage_id=len(gage_ids_str), axis=-1))\n",
    "\n",
    "template = template.assign_coords({'gage_id':[f'USGS-{gage_id}' for gage_id in gage_ids_str]})\n",
    "\n",
    "template = template.chunk({'time':len(ds_obs.time), 'gage_id': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858689f1-3160-4f06-be9a-19478639c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc8652-b257-4751-afe5-c0172a84e04d",
   "metadata": {},
   "source": [
    "Specify appropriate dtypes and fill values (otherwise int64 and float64 are used by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45893e71-2f5d-49be-b634-fba677641050",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {'alt_acy_va': dict(_FillValue=-2147483647, dtype=np.int32),\n",
    "            'alt_va': dict( _FillValue=9.96921e+36, dtype=np.float32),\n",
    "            'dec_lat_va': dict( _FillValue=None, dtype=np.float32),\n",
    "            'dec_long_va': dict( _FillValue=None, dtype=np.float32),\n",
    "            'streamflow': dict( _FillValue=9.96921e+36, dtype=np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0628dc7-b35e-4591-b347-494a1ae7d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes no data (yet)\n",
    "template.to_zarr(file_chanobs, compute=False, encoding=encoding, consolidated=True, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc9a53-c534-426d-8f29-23fa8f9907f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = len(ds_obs.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2acaf-7628-4c4a-aa97-9582d74d334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_obs.to_zarr(file_chanobs, region={'time':slice(0, nt), 'gage_id': slice(0, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadd650-f1ff-4f21-9c2e-ce5d92bc54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ind2zarr(n):\n",
    "     site_id = gage_ids_str[n]\n",
    "     try:\n",
    "        ds_obs = nwis.get_streamflow(site_id, dates, to_xarray=True).interp(time=time_base)\n",
    "        ds_obs = ds_obs.rename_dims({'station_id':'gage_id'}).rename({'station_id':'gage_id','discharge':'streamflow'})\n",
    "        ds_obs.to_zarr(file_chanobs, region={'time': slice(0, nt), 'gage_id': slice(n,n+1)})\n",
    "     except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7a735-6690-4022-a7bf-0022fc25244a",
   "metadata": {},
   "source": [
    "### Use a Dask cluster to make NWIS station requests in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01d30a-ee17-483e-8227-6a9202883bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = 'tallgrass' #choose from denali, tallgrass, local, esip-qhub-gateway-v0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a973e98-4968-4c47-b31d-5f04d92d01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = os.environ['SLURM_JOB_ACCOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26607c5f-6cc6-4fa8-920b-0314b41ff817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_cluster(resource):\n",
    "    ''' Helper function to configure cluster\n",
    "    '''\n",
    "    if resource == 'denali':\n",
    "        cluster = LocalCluster(threads_per_worker=1)\n",
    "        client = Client(cluster)\n",
    "    \n",
    "    elif resource == 'tallgrass':\n",
    "        project = os.environ['SLURM_JOB_ACCOUNT']\n",
    "        \n",
    "        cluster = SLURMCluster(processes=1,cores=1, \n",
    "            memory='10GB', interface='ib0',\n",
    "            project=project, walltime='01:00:00',      \n",
    "            job_extra={'hint': 'multithread'})\n",
    "        cluster.scale(10)\n",
    "        client = Client(cluster)\n",
    "        \n",
    "    elif resource == 'local':\n",
    "        import warnings\n",
    "        warnings.warn(\"Running locally can result in costly data transfers!\\n\")\n",
    "        n_cores = os.cpu_count() # set to match your machine\n",
    "        cluster = LocalCluster(threads_per_worker=n_cores)\n",
    "        client = Client(cluster)\n",
    "        \n",
    "    elif resource in ['esip-qhub-gateway-v0.4']:   \n",
    "        import sys\n",
    "        sys.path.append(os.path.join(os.environ['HOME'],'shared','users','lib'))\n",
    "        import ebdpy as ebd\n",
    "        ebd.set_credentials(profile='esip-qhub')\n",
    "\n",
    "        aws_profile = 'esip-qhub'\n",
    "        aws_region = 'us-west-2'\n",
    "        endpoint = f's3.{aws_region}.amazonaws.com'\n",
    "        ebd.set_credentials(profile=aws_profile, region=aws_region, endpoint=endpoint)\n",
    "        worker_max = 30\n",
    "        client,cluster = ebd.start_dask_cluster(profile=aws_profile, worker_max=worker_max, \n",
    "                                              region=aws_region, use_existing_cluster=True,\n",
    "                                              adaptive_scaling=False, wait_for_cluster=False, \n",
    "                                              worker_profile='Medium Worker', propagate_env=True)\n",
    "        \n",
    "    return client, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e02b74-8afa-4259-a7fc-53c682c0744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client, cluster = configure_cluster(resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a440e-4478-4b73-a0c5-aa62744db00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b369d99-28ba-4b8b-8f68-970352ecf6b6",
   "metadata": {},
   "source": [
    "### Begin saving and writing data\n",
    "This is where all the work gets done (a list of delayed tasks is created and then executed by the Dask cluster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ddaba-dfad-4519-aca4-9eb0cb64ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# takes less than 5 minutes with a local cluster on Denali:\n",
    "_ = dask.compute(*[dask.delayed(ind2zarr)(i) for i in range(len(gage_ids_str))], retries=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f1555-8429-426c-b674-a52bff8a8451",
   "metadata": {},
   "source": [
    "Call Zarr convenience function to consolidate the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1c9d0-7a01-496e-85cc-7cab8328a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = consolidate_metadata(file_chanobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed5324d-2793-4699-bd39-c449e85f7c32",
   "metadata": {},
   "source": [
    "#### Check out the resulting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5236e-98fa-4f83-bebd-c9b01c5da8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename and path check, where the NWIS data is now stored.\n",
    "file_chanobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ad89e-e398-4014-ae25-2f39dcea9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = xr.open_dataset(file_chanobs, engine='zarr', chunks={}, backend_kwargs=dict(consolidated=True))\n",
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb57d17-8dc5-4c82-bd5d-52c2f8b442a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out a plot of the discharge over time for a random gage in the list:\n",
    "dst.streamflow.isel(gage_id=100).hvplot(x='time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6e86d-d868-4221-8bd9-8fcf6b59d47f",
   "metadata": {},
   "source": [
    "All done, close client and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6308f2-867e-46ee-a1c0-abf67646d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close(); cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
