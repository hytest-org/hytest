{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1be096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import os\n",
    "import tempfile\n",
    "import xarray as xr\n",
    "\n",
    "from nco import Nco\n",
    "from nco.custom import Atted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118de47c-2b56-4348-905b-08b7a280f58a",
   "metadata": {},
   "source": [
    "# Processing netCDF files\n",
    "This notebook documents two approaches to processing netCDF files \n",
    "with `pyNCO` (https://pynco.readthedocs.io/en/latest/). \n",
    "The gridmet product (https://www.climatologylab.org/gridmet.html) is used for these examples. \n",
    "The gridmet files contain one variable per year. This notebook shows examples of merging those files \n",
    "into a single, multi-year file containing all variables.\n",
    "\n",
    "In the first approach the management of the temporary files is done manually. In this case care must be taken to \n",
    "track the temporary files, avoiding file collisions (e.g. accidently overwriting temporary files) and removing \n",
    "the files once processing is done.\n",
    "\n",
    "The second approach makes use of the `tempfile` library which automates the use and handling of the temporary \n",
    "files needed during processing. Temporary files are automatically removed at the end of the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009eb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample gridmet filename: 2020_gm_tmin_2021_03_31.nc\n",
    "#     year ----------------^^^^\n",
    "#     variable --------------------^^^^\n",
    "#     date retrieved -------------------^^^^^^^^^^\n",
    "\n",
    "var = 'tmin'\n",
    "base_dir = '/Volumes/USGS_NHM2/datasets/gridmet'\n",
    "src_dir = f'{base_dir}/gridmet_raw'\n",
    "output_dir = f'{base_dir}/test_output'\n",
    "\n",
    "output_filename = f'gridmet_{var}_1979-2020'    # .nc is added later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe9cb10-364b-46f2-bcc7-72beebd47334",
   "metadata": {},
   "source": [
    "## Using pyNCO with manual temporary file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NCO object\n",
    "# Setting debug=True will output information about the nco execution that can be useful\n",
    "# when examining problems in the processing scripts.\n",
    "nco = Nco(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a filesystem\n",
    "fs = fsspec.filesystem('file')\n",
    "\n",
    "# Build list of gridmet files\n",
    "flist = sorted(fs.glob(f'{src_dir}/*_gm_{var}_*.nc'))\n",
    "print(flist[0])\n",
    "print(flist[-1])\n",
    "len(flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb82522",
   "metadata": {},
   "source": [
    "NOTE (2022-01): This notebook works from the original retrieved Gridmet data (on denali). \n",
    "This data was saved in netCDF Classic format but still included the _ChunkSizes attribute which \n",
    "confuses some tools. Removing the attribute can be done in-place if you have read-write access to the files; \n",
    "otherwise you have to make a copy of the original files without the _ChunkSizes attribute. \n",
    "More recent versions of the gridmet data do not have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original NCO command\n",
    "# ncatted -a _ChunkSizes,,d,, ${ff}\n",
    "\n",
    "# opts = ['-a _ChunkSizes,,d,,']\n",
    "# nco.ncatted(input=somefile.nc)\n",
    "\n",
    "opts = ['-h', Atted(mode='delete', att_name='_ChunkSizes')]\n",
    "\n",
    "for ff in flist[0:2]:\n",
    "    nco.ncatted(input=ff, options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67e258-94a8-4aa6-a7a8-5f766bfd077f",
   "metadata": {},
   "source": [
    "### Change fixed time dimension to record dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d198e",
   "metadata": {},
   "source": [
    "The original Gridmet data has a fixed time dimension named `day`. In order to concatenate individual files \n",
    "(1 year, 1 variable per file) into a single file per variable for the period of record we need to change the \n",
    "fixed time dimension into an unlimited record dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e339c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ncks -O --mk_rec_dmn day ${ff} -o merged/${ff}\n",
    "\n",
    "# Adding -h prevents adding entries into the global history\n",
    "record_dim = 'day'\n",
    "opts = [f'-O -h --mk_rec_dmn {record_dim}']\n",
    "\n",
    "for ff in flist[0:2]:\n",
    "    tmp_file = f'tmp_{os.path.basename(ff)}'\n",
    "    print(f'Processing {tmp_file}')\n",
    "    \n",
    "    nco.ncks(input=ff, output=f'{output_dir}/{tmp_file}', options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b295604-2f24-42ad-bb93-88e21949da71",
   "metadata": {},
   "source": [
    "### Concatenate single-year files into a single multi-year file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf764d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ncrcat ${var}.nc -o gridmet_${var}_1979-2020.nc\n",
    "\n",
    "o_flist = sorted(fs.glob(f'{output_dir}/*.nc'))\n",
    "\n",
    "# The -h option prevents the netCDF operators tools from automatically appending to the \n",
    "# global history attribute. Otherwise the history can get rather large and messy.\n",
    "opts = ['-h']\n",
    "\n",
    "nco.ncrcat(input=o_flist, output=f'{output_dir}/{var}.nc', options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbd458-5ba0-434f-a358-63d962cb948d",
   "metadata": {},
   "source": [
    "### Create simplified global history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5905d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simplified/sanitized history entry\n",
    "input_files = ' '.join([os.path.basename(ff) for ff in o_flist])\n",
    "history_text = f'ncrcat {input_files} -o {var}.nc'\n",
    "\n",
    "opts = ['-h', Atted(mode='append', att_name='history', var_name='global', value=history_text, stype='c')]\n",
    "\n",
    "# When only the input argument is specified for the ncatted command the\n",
    "# attribute editing is done in-place.\n",
    "xx = nco.ncatted(input=f'{output_dir}/{var}.nc', options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fcae88",
   "metadata": {},
   "source": [
    "### Rechunk the concatenated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc64c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ncks -O -4 -L 2 --cnk_map=dmn --cnk_dmn day,122 --cnk_dmn lat,98 --cnk_dmn lon,231 ${ff} -o ../${ff}\n",
    "time_cnk = 122\n",
    "lat_cnk = 98\n",
    "lon_cnk = 231\n",
    "\n",
    "opts = ['-O', '-4', '-L 2', \n",
    "        '--cnk_map=dmn', \n",
    "        f'--cnk_dmn {record_dim},{time_cnk}',\n",
    "        f'--cnk_dmn lat,{lat_cnk}', \n",
    "        f'--cnk_dmn lon,{lon_cnk}']\n",
    "\n",
    "nco.ncks(input=f'{output_dir}/{var}.nc', output=f'{output_dir}/{output_filename}.nc', options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fee40-b32f-42aa-ae43-119330a72d2a",
   "metadata": {},
   "source": [
    "### Explore the merged netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f'{output_dir}/{output_filename}.nc', chunks='auto')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine one of the variables\n",
    "ds.daily_minimum_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46771256",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafc689",
   "metadata": {},
   "source": [
    "# Using pyNCO with automatic temporary file management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0b61e",
   "metadata": {},
   "source": [
    "Here we create a temporary directory to contain the intermediate files. The directory and its contents are \n",
    "automatically removed once the code block has completed. The final output file is written to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795bd61",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# When clean_history is true the original global history attribute contents are cleared and replaced with\n",
    "# only the history related to our processing.\n",
    "clean_history = True\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    print(f'Working in {tmp_dir}')\n",
    "    \n",
    "    # Make the time dimension a record dimension\n",
    "    print('    Make record dimension')\n",
    "    record_dim = 'day'\n",
    "    opts = [f'-O --mk_rec_dmn {record_dim}']\n",
    "\n",
    "    for ff in flist[0:2]:\n",
    "        tmp_filename = f'tmp_{os.path.basename(ff)}'\n",
    "        print(f'Processing {tmp_filename}')\n",
    "\n",
    "        nco.ncks(input=ff, output=f'{tmp_dir}/{tmp_filename}', options=opts)\n",
    "        \n",
    "    # Concatenate the individual files\n",
    "    print('    Concatenate files')\n",
    "    o_flist = sorted(fs.glob(f'{tmp_dir}/*.nc'))\n",
    "\n",
    "    nco.ncrcat(input=o_flist, output=f'{tmp_dir}/{var}_concat.nc')   # , options=opts)        \n",
    "        \n",
    "    # Rechunk the data\n",
    "    print('    Rechunk data')\n",
    "    time_cnk = 122\n",
    "    lat_cnk = 98\n",
    "    lon_cnk = 231\n",
    "\n",
    "    opts = ['-O', '-4', '-L 2', \n",
    "            '--cnk_map=dmn', \n",
    "            f'--cnk_dmn {record_dim},{time_cnk}',\n",
    "            f'--cnk_dmn lat,{lat_cnk}', \n",
    "            f'--cnk_dmn lon,{lon_cnk}']\n",
    "\n",
    "    nco.ncks(input=f'{tmp_dir}/{var}_concat.nc', output=f'{output_dir}/{output_filename}.nc', options=opts)\n",
    "    \n",
    "    if clean_history:\n",
    "        print('    Clean history')\n",
    "        # Read the final file and create a modified history\n",
    "        ds = xr.open_dataset(f'{output_dir}/{output_filename}.nc', chunks='auto')\n",
    "\n",
    "        history = ds.attrs['History']\n",
    "        aa = history.split('\\n')\n",
    "\n",
    "        new_hist = []\n",
    "\n",
    "        for io, dd in enumerate(aa):\n",
    "            bb = dd.split()\n",
    "            keep = True\n",
    "\n",
    "            for ii, cc in enumerate(bb):\n",
    "                if cc in ['ncatted']:\n",
    "                    keep = False\n",
    "                    continue\n",
    "                elif '--output' in cc:\n",
    "                    bb[ii] = '--output=' + os.path.basename(cc.split('=')[1])\n",
    "                else:\n",
    "                    if os.path.isfile(cc):\n",
    "                        bb[ii] = os.path.basename(cc)\n",
    "            if keep:\n",
    "                new_hist.append(' '.join(bb))\n",
    "\n",
    "        ds.close()\n",
    "        \n",
    "        # Remove History global attribute\n",
    "        opts = ['-h', Atted(mode='delete', att_name='History', var_name='global')]\n",
    "        nco.ncatted(input=f'{output_dir}/{output_filename}.nc', options=opts)        \n",
    "        \n",
    "        # Add new history global attribute (all lowercase)\n",
    "        # NOTE: the double backslash for the value argument is needed so that \\n is passed to ncatted correctly\n",
    "        opts = ['-h', Atted(mode='create', att_name='history', var_name='global', \n",
    "                            value='\\\\n'.join(new_hist), stype='c')]\n",
    "        nco.ncatted(input=f'{output_dir}/{output_filename}.nc', options=opts)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa938d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python [conda env:nco]",
   "language": "python",
   "name": "conda-env-nco-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
