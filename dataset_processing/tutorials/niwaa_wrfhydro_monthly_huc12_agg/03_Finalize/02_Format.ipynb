{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53586f07-4c25-41b6-aaf0-e45778850258",
   "metadata": {},
   "source": [
    "## Finalize the output files\n",
    "\n",
    "Edit variable names, metadata, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2ef0f-222e-4db7-a48c-4d521b2d92a5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc0451-5400-475c-a9d5-e426c56f8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Modules --- #\n",
    "\n",
    "# Import Python Core Modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Import Additional Modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "tic = time.time()\n",
    "print('Process initiated at {0}'.format(time.ctime()))\n",
    "# --- End Import Modules --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6ce3b-b7d2-4a18-bfb9-7ded2c244d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_nc = r'/path/to/outputs/agg_out/CONUS_HUC12_WB_combined_19791001_20220930.nc'\n",
    "\n",
    "# Output directory\n",
    "outDir = r'/path/to/outputs/agg_out/'\n",
    "\n",
    "# Output files\n",
    "out_nc = os.path.join(outDir, 'huc12_monthly_wb_iwaa_wrfhydro_WY2011_2013.nc')\n",
    "#out_csv = os.path.join(outDir, 'huc12_monthly_wb_iwaa_wrfhydro_WY2011_2013_2.csv')\n",
    "\n",
    "# Select output formats\n",
    "write_NC = True      # Output netCDF file\n",
    "#write_CSV = True     # Output CSV file\n",
    "\n",
    "# Name the zone dimension\n",
    "zone_name = 'WBDHU12'\n",
    "\n",
    "# Name the time dimension\n",
    "time_coord = 'time'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d734df8e-aa54-43fe-a78d-375ee579c2de",
   "metadata": {},
   "source": [
    "### Dictionaries to rename variables and set attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779ebcd-fa22-4957-88f4-a5eb4a32fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to rename variables. Also used to subset dataset by variable name.\n",
    "var_rename_dict = {'totPRECIP':'Precip',\n",
    "                   'totPRECIP':'PrecipLand',\n",
    "                   'deltaACSNOW':'Snowfall',\n",
    "                   'totqSfcLatRunoff':'Surfaceflow',\n",
    "                   'totqBucket':'Baseflow',\n",
    "                   'deltaACCET':'ET',\n",
    "                   'avgSNEQV':'SWE',\n",
    "                   'avgSOILM':'SoilWater',\n",
    "                   'avgSOILSAT':'SoilSat',\n",
    "                   'deltaUGDRNOFF':'Recharge',\n",
    "                   'bucket_depth':'GWStore',\n",
    "                   'Area_sqkm':'CatchmentArea',\n",
    "                   'Precip':'Precip',\n",
    "                   'landmask':'LandFraction',\n",
    "                   'total_gridded_area': 'total_gridded_area',\n",
    "                   'avgSOILM_wltadj_depthmean': 'avgSOILM_wltadj_depthmean',\n",
    "                   'avgSOILSAT_wltadj_top1': 'avgSOILSAT_wltadj_top1',}\n",
    "\n",
    "# Rename dimensions\n",
    "rename_dim_dict = {zone_name:'huc_id'}\n",
    "\n",
    "# Variable attributes dictionary\n",
    "var_atts_dict = {'Precip':{'units':'mm',\n",
    "                           'long_name':\"Total monthly precipitation (land & water)\"},\n",
    "                'PrecipLand':{'units':'mm',\n",
    "                              'long_name':\"Total monthly precipitation (land only)\"},\n",
    "                'Snowfall':{'units':'mm',\n",
    "                            'long_name':\"Total monthly snowfall (land only)\"},\n",
    "                'Surfaceflow':{'units':'mm',\n",
    "                               'long_name':\"Total monthly surface flow\"},\n",
    "                'Baseflow':{'units':'mm',\n",
    "                            'long_name':\"Total monthly baseflow\"},\n",
    "                'ET':{'units':'mm',\n",
    "                      'long_name':\"Total monthly evapotranspiration (land only)\"},\n",
    "                'SWE':{'units':'mm',\n",
    "                       'long_name':\"Average monthly snow water equivalent (land only)\"},\n",
    "                'SoilWater':{'units':'mm',\n",
    "                             'long_name':\"Average monthly soil moisture in 2m soil column (land only)\"},\n",
    "                'SoilSat':{'units':'fraction',\n",
    "                           'long_name':\"Average monthly fractional soil saturation in 2m soil column (land only)\"},\n",
    "                'Recharge':{'units':'mm',\n",
    "                            'long_name':\"Total monthly recharge (land only)\"},\n",
    "                'GWStore':{'units':'mm',\n",
    "                           'long_name':\"Average monthly groundwater store\"},\n",
    "                'LandFraction':{'units':'fraction',\n",
    "                                'standard_name':'area_fraction',\n",
    "                                'long_name':\"Land fraction of HUC12 from gridded data\"},\n",
    "                'CatchmentArea':{'units':'square kilometers',\n",
    "                                 'long_name':\"Total NWM catchment area (square kilometers)\"},\n",
    "                }\n",
    "\n",
    "# Global attributes dictionary\n",
    "out_global_atts = {'title':\"HUC12 monthly WRF-Hydro modeling application\",\n",
    "                   'institution':\"USGS\",\n",
    "                   'history':\"Author, {}\".format(time.ctime())\n",
    "                  }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8edb64-50c0-40f9-8b50-07ac04ba9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(in_nc)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b6b01-3c9a-41e9-81da-c9c9f04ed2dc",
   "metadata": {},
   "source": [
    "### Code to add back in Char HUCIDs from source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697019f9-6b78-48f8-a4c9-f9cfa8fbe3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert the HUC dataset (polygons) to WGS84 to match the points\n",
    "HUC_gpkg = r'/caldera/hovenweep/projects/usgs/water/impd/hytest/niwaa_wrfhydro_monthly_huc12_aggregations_sample_data/HUC12_grids/HUC12.gpkg'\n",
    "HUC_gdf = gpd.read_file(HUC_gpkg, layer='WBDHU12_CONUS', ignore_geometry=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30aac7-2f72-4984-a08e-cdee92c656b0",
   "metadata": {},
   "source": [
    "### Assign the coordinates to match the string-type HUC12 IDs from the input feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af608308-8ff2-43cf-b779-afbf45bef441",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a new dataframe with just the HUC12 data\n",
    "HUC_df = HUC_gdf[['HUC12', 'AREASQKM', 'STATES', 'TOHUC']].copy()\n",
    "\n",
    "# Create new field that will match to the datatype in the input file\n",
    "HUC_df['HUC12_int'] = HUC_df['HUC12'].astype(np.int64)\n",
    "\n",
    "# Export the netCDF coordinate to a dataframe\n",
    "nc_df = ds['WBDHU12'].to_dataframe()\n",
    "nc_df.index = np.arange(nc_df.shape[0]) #reset_index()\n",
    "combined_df = pd.merge(nc_df, HUC_df,  how='inner', left_on=['WBDHU12'], right_on=['HUC12_int'])\n",
    "\n",
    "# Deal with duplicates\n",
    "combined_df = combined_df[~combined_df.duplicated(subset=['HUC12_int'], keep='last')]\n",
    "\n",
    "# Make sure they have the same number of values\n",
    "assert combined_df['HUC12'].unique().shape == nc_df['WBDHU12'].unique().shape\n",
    "\n",
    "# Make sure they are identical\n",
    "assert (combined_df['HUC12_int'] == ds['WBDHU12'].data).sum() == ds['WBDHU12'].data.shape\n",
    "\n",
    "da = xr.DataArray(combined_df['HUC12'].astype('S12'), coords={'WBDHU12': combined_df['HUC12'].astype('S12')},dims=['WBDHU12'])\n",
    "ds['WBDHU12'] = da\n",
    "#del da, HUC_df, combined_df, nc_df, HUC_gdf\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c552fd7-c023-4fd8-84c9-355ba5bdffdf",
   "metadata": {},
   "source": [
    "### Rename variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269a382-100c-4830-885f-c5b8d4405939",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ds.rename_vars(var_rename_dict)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548e404-7f1c-4b4e-8605-4d438194a6dd",
   "metadata": {},
   "source": [
    "### Rename Dimensions and coordinate variables\n",
    "\n",
    "Using `xr.rename` instead of `xr.rename_dims` ensures that any coordinate variables are also renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4ecd7-6c6a-4623-a81a-323a8f9aae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ds_out.rename(rename_dim_dict)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b22a65-0698-437c-9d9a-1c618925978c",
   "metadata": {},
   "source": [
    "### Subset variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0bd4c-3718-4ac9-ab68-829623d1e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ds_out[list(var_rename_dict.values())]\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ee22b-7e36-41d5-b468-41e4adbc5831",
   "metadata": {},
   "source": [
    "### Change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce004f79-76d9-4547-9974-5331eff7f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ds_out.data_vars:\n",
    "    if ds_out[variable].dtype == np.float64:\n",
    "        print('Found a float64 for variable {0}'.format(variable))\n",
    "        ds_out[variable] = ds_out[variable].astype(np.float32)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54febd5c-6260-4840-951f-887acee25436",
   "metadata": {},
   "source": [
    "### Re-order dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ff0cc-e14f-4b7d-ad22-6726eb71e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ds_out.data_vars:\n",
    "    #print(variable, ds_out[variable].dims)\n",
    "    if ds_out[variable].dims == ('time', 'huc_id'):\n",
    "        print('Var {0} not correct: {1}'.format(variable, ds_out[variable].dims))\n",
    "        ds_out[variable] = ds_out[variable].transpose()\n",
    "        #ds_out[variable] = ds_out[variable][['huc_id', 'time', variable]]\n",
    "ds_out.load()\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bcfa5-9b32-4b44-bb61-153b5e0a3a04",
   "metadata": {},
   "source": [
    "### Set variable and global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73657e0d-e5e7-442e-9f15-b7749d89da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate any unecessary variable attributes (such as spatial metadata)\n",
    "for variable in ds_out.data_vars:\n",
    "    if variable in var_atts_dict:\n",
    "        ds_out[variable].attrs = var_atts_dict[variable]\n",
    "\n",
    "# Now eliminate unnecessary global attributes \n",
    "ds_out.attrs = out_global_atts\n",
    "\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68e028-6aa3-450c-ad60-59d3c8b97597",
   "metadata": {},
   "source": [
    "### Reorganize time dimension to year and month dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adbd62-0582-4f64-acfc-29e8a7249336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret times as strings - for later input to CSV files as a time index\n",
    "datetime_strings = [pd.to_datetime(ds_out['time']).strftime('%Y%m%d%H')]\n",
    "\n",
    "# year-month strings\n",
    "yearmo_strings = [pd.to_datetime(ds_out['time']).strftime('%Y-%m')]\n",
    "yearmo_strings\n",
    "\n",
    "ds_out['yrmo'] = xr.DataArray(np.array(yearmo_strings, dtype='U'), dims=('yrmo_index', time_coord), name='yrmo')\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b267f-f0c8-4d60-84f3-e5baf983b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the nodata value\n",
    "nodata_value = float(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8167a04-db7d-49c8-9faf-ac9eda726de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unecessary dimension on `yrmo` variable\n",
    "yrmo_dim_len = [len(ds_out[dim]) for dim in ds_out['yrmo'].dims]\n",
    "if len(ds_out['yrmo'].dims) > 1 and 1 in yrmo_dim_len:\n",
    "   remove_dims = [dim for dim in ds_out['yrmo'].dims if len(ds_out[dim])==1]\n",
    "   print('Removing dimension(s) {0} from variable \"yrmo\".'.format(remove_dims))\n",
    "   ds_out['yrmo'] = ds_out['yrmo'].squeeze()\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1f34c-05df-4b4a-b616-277a569b8d27",
   "metadata": {},
   "source": [
    "5) Enforce a sort order on the variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026157a-e4a7-4c07-8bb3-cd749e2fc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build list of variables, sorted by 1D, then 2D alphabetical\n",
    "sorted_varlist = ['yrmo', 'CatchmentArea', 'LandFraction', 'total_gridded_area']\n",
    "\n",
    "# Build list of all 2D+ variables, sorted alphabetically no matter the case\n",
    "sorted_varlist2 = [item for item in list(ds_out.data_vars) if item not in sorted_varlist]\n",
    "sorted_varlist2.sort(key=str.casefold)\n",
    "\n",
    "# Add the lists together\n",
    "sorted_varlist += sorted_varlist2\n",
    "assert len(list(ds_out.data_vars)) == len(sorted_varlist)\n",
    "print('Found {0} variables. Sorted by number of dimensions and then alphabetically'.format(len(sorted_varlist)))\n",
    "      \n",
    "# Sort the variables in the dataset\n",
    "out_ds = ds_out[sorted_varlist]\n",
    "out_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d43716-82fb-43f8-869d-985aa5e27cb6",
   "metadata": {},
   "source": [
    "### 6) Fix NoData Issues\n",
    "\n",
    "A decision was made to make all NaN values consistent between 10-year and 40-year Water Budget component files, using -9999.0 as the _FillValue in the netCDF files, and adding descirptions to variable attributes to identify what NaN means in each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad76b06-a08a-4255-9313-a1aa5f89c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fix variable attributes and encodings\n",
    "output_encoding = {}\n",
    "for data_var in out_ds.data_vars:\n",
    "    print(data_var)\n",
    "\n",
    "    # Fix nodata description attribute\n",
    "    if data_var in ['PrecipLand', \n",
    "                    'Snowfall', \n",
    "                    'ET', \n",
    "                    'SWE', \n",
    "                    'SoilWater', \n",
    "                    'SoilSat', \n",
    "                    'Recharge', \n",
    "                    'Precip', \n",
    "                    'LandFraction', \n",
    "                    'total_gridded_area', \n",
    "                    'avgSOILM_wltadj_depthmean', \n",
    "                    'avgSOILSAT_wltadj_top1']:\n",
    "        out_ds[data_var].attrs['nodata_description'] = 'HUC12 contains no land cells'\n",
    "    elif data_var in ['CatchmentArea']:\n",
    "        out_ds[data_var].attrs['nodata_description'] = 'HUC12 contains no WRF-Hydro catchment polygons'\n",
    "    elif data_var in ['Surfaceflow', \n",
    "                      'Baseflow', \n",
    "                      'GWStore']:\n",
    "        out_ds[data_var].attrs['nodata_description'] = 'HUC12 contain no WRF-Hydro flowlines.'\n",
    "    else:\n",
    "        continue\n",
    "    print('\\tnodata_description: {0}'.format(out_ds[data_var].attrs['nodata_description']))\n",
    "\n",
    "    # Change NaN to nodata value\n",
    "    nodata_mask = out_ds[data_var].isnull().data\n",
    "    print('\\tFound {0} nodata values'.format(nodata_mask.sum()))\n",
    "    #display(out_ds[data_var].data[nodata_mask])\n",
    "    out_ds[data_var].data[nodata_mask] = nodata_value\n",
    "    #display(out_ds[data_var].data[nodata_mask])\n",
    "    \n",
    "    # Variable encoding\n",
    "    out_ds[data_var].encoding['_FillValue'] = nodata_value\n",
    "    output_encoding[data_var] = {'_FillValue':nodata_value}\n",
    "\n",
    "    # Remove redundant missing value encoding\n",
    "    if 'missing_value' in out_ds[data_var].encoding:\n",
    "        del out_ds[data_var].encoding['missing_value']\n",
    "    print('\\t'.format(out_ds[data_var].encoding['_FillValue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1e1f1-032d-4815-a366-68ac0329571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the variable encodings\n",
    "for var in out_ds.data_vars:\n",
    "    print(var)\n",
    "    for key,item in out_ds[var].encoding.items():\n",
    "        print(f'    {key}: {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfdf485-d748-4991-9f40-e2306412ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('  Writing output to {0}'.format(out_nc))\n",
    "out_ds.compute()\n",
    "out_ds.to_netcdf(out_nc, encoding=output_encoding)\n",
    "out_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863794c-5029-4e5b-be66-e044cba28c4d",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4dcdb-fc53-4977-9d7c-6e1a4fc05907",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()\n",
    "ds_out.close()\n",
    "print('Process completed in {0: 3.2f} seconds.'.format(time.time()-tic))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
