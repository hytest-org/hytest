{"version":3,"kind":"Article","sha256":"c78501d803affa535c15c93c70b9b8cbf2a3fb2760889c0a46ffb7c261173c0f","slug":"essential-reading.datasources.data-apis","location":"/essential_reading/DataSources/Data_APIs.md","dependencies":[],"frontmatter":{"title":"Data/APIs","content_includes_title":false,"github":"https://github.com/hytest-org/hytest","copyright":"2023","numbering":{"title":{"offset":2}},"source_url":"https://github.com/hytest-org/hytest/blob/main/essential_reading/DataSources/Data_APIs.md","edit_url":"https://github.com/hytest-org/hytest/edit/main/essential_reading/DataSources/Data_APIs.md","exports":[{"format":"md","filename":"Data_APIs.md","url":"/hytest//build/Data_APIs-a351d54d1dec27364a045356f02ca035.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Application Programming Interfaces (API) are a common way of accessing and processing\ndata over the internet between a distant application and the application (or script)\nyou are working on. Another method is File Transfer Protocol calls (FTP), which are\nused to transfer large amounts of data over the internet. As FTPs are not communications\nbetween applications but just simple data tranfers with no processing capabilities, they\nare being used less and less over time, though some data is still only available over\nthe internet in this fashion.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qNfYUE3cLu"}],"key":"REzxQGm2Q2"},{"type":"heading","depth":2,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"API","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"IRCxv4OGaZ"}],"key":"dBsSWHAmyS"}],"identifier":"api","label":"API","html_id":"api","implicit":true,"key":"kRY9Sypddg"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"In Python, there are different ways of getting data with APIs and we will examine two of the more common: using a library such as ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Z4C6j5KQfg"},{"type":"inlineCode","value":"requests","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"CWZtjzeEnb"},{"type":"text","value":" to query the API or use a library a developer has created to make interacting with an API easier, such as ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"n1FVoB0wSw"},{"type":"inlineCode","value":"pygeohydro","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"aW1NXjq6Yy"},{"type":"text","value":", through different helper functions or improved documentation.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"AUkmLL8F11"}],"key":"AW876EVpBV"},{"type":"heading","depth":3,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"inlineCode","value":"requests","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"WZ9g6IO0Lb"}],"identifier":"requests","label":"requests","html_id":"requests","implicit":true,"key":"NNB6Cz12Ux"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"FNZNE3n6sr"},{"type":"inlineCode","value":"requests","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"FrVQKjyQGp"},{"type":"text","value":" library is a ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"r8Lsux7xGA"},{"type":"link","url":"https://requests.readthedocs.io/en/latest/","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"well documented library","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"d4U0aLcDDQ"}],"urlSource":"https://requests.readthedocs.io/en/latest/","key":"CdLzy1dUz2"},{"type":"text","value":" for issuing ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"vOc4kFJb4J"},{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"get","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"SGOv5iIl6a"}],"key":"oW35lpeh5p"},{"type":"text","value":" requests.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"pqrdz0Lns0"}],"key":"eq4MfyJjZs"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"A common example in geospatial work is getting data from ArcGIS Feature Service layers and\ncreating a ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"Gm4eqh9hft"},{"type":"inlineCode","value":"geopandas GeoDataFrame","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"i2A64EQq7J"},{"type":"text","value":" from it. The typical process for accomplishing this is\nusing a combination of the REST API page, the REST API query page to help build a query\n(if available), and an ArcGIS Online view of the data for help understanding the contents\nof fields. An example is the\n","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"toyrFJhoKS"},{"type":"link","url":"https://hub.arcgis.com/datasets/CC-NY::wbdhu10-watershed/explore?location=42.219929%2C-73.252807%2C9.00","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"HUC10 Watershed","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"EypVwFN6eT"}],"urlSource":"https://hub.arcgis.com/datasets/CC-NY::wbdhu10-watershed/explore?location=42.219929%2C-73.252807%2C9.00","key":"meJ8TDnsFk"},{"type":"text","value":"\nby Columbia County Planning. The dataset can be explored using the included map and an comes\nwith an ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"YE3EgaTfrV"},{"type":"link","url":"https://hub.arcgis.com/datasets/CC-NY::wbdhu10-watershed/api","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"API Explorer","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"V7hkGftioa"}],"urlSource":"https://hub.arcgis.com/datasets/CC-NY::wbdhu10-watershed/api","key":"OIZ5mAHOX8"},{"type":"text","value":" to help build the API.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"wFTp0g6RXh"}],"key":"PTV72W3SVp"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Putting this all together would look like this:","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"z0A6LdxTp1"}],"key":"TmHSbc54AJ"},{"type":"code","lang":"python","value":"import requests\nimport geopandas as gpd\n\n# create base url and paylaod\nbase_url = \"https://services3.arcgis.com/F5762GA30C3SyZFy/arcgis/rest/services/Watershed_Boundary_Dataset/FeatureServer/4/query?\"\npayload = {\"where\":\"1=1\", #all records that match\n    \"returnGeometry\":\"true\",\n    \"outFields\": \"*\",\n    \"outSR\":\"4326\", #WGS84\n    \"f\": \"pjson\" #f=format\n}\n\n# send request, which will create URL\nr = requests.get(base_url, params=payload)\n\n# check that get was successful before creating GeoDataFrame\nif r.status_code == 200: #200 == success\n    gdf = gpd.read_file(r.text)\nelse:\n    print(f\"Request failed. Status code = {r.status_code}\")\n\n# plot to see the geometries\ngdf.plot()","position":{"start":{"line":30,"column":1},"end":{"line":54,"column":1}},"key":"jVQoWqzT3A"},{"type":"paragraph","position":{"start":{"line":56,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Some FeatureServers have preformatted data calls that return the data as a GeoJSON without\nhaving to construct a payload as above.  The request URL has the query parameters built in.\nThis can be read directly into a GeoDataFrame.","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"JXZPWvWYio"}],"key":"dAvgmvOYXI"},{"type":"paragraph","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"A request similar to the above would look like this with a GeoJSON API request using such a service:","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"nIvC4mIXw8"}],"key":"sYDJQeEQVm"},{"type":"code","lang":"python","value":"import geopandas as gpd\n\nurl = \"https://services3.arcgis.com/F5762GA30C3SyZFy/arcgis/rest/services/Watershed_Boundary_Dataset/FeatureServer/4/query?outFields=*&where=1%3D1&f=geojson\"\n\n# create GeoDataFrame\ngdf = gpd.read_file(url)\n\n# plot to see the geometries\ngdf.plot()","position":{"start":{"line":62,"column":1},"end":{"line":72,"column":1}},"key":"vYRMe6dBiY"},{"type":"heading","depth":3,"position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"inlineCode","value":"pygeohydro","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"Gs3JwLJrMH"}],"identifier":"pygeohydro","label":"pygeohydro","html_id":"pygeohydro","implicit":true,"key":"nl4zq3eMK1"},{"type":"paragraph","position":{"start":{"line":76,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"Libraries like ","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"yUCm00apMl"},{"type":"link","url":"https://docs.hyriver.io/autoapi/pygeohydro/index.html","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"pygeohydro","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"khln5at2bv"}],"urlSource":"https://docs.hyriver.io/autoapi/pygeohydro/index.html","key":"lY23MbsT9a"},{"type":"text","value":" provide\neasy ways to format data calls to data services via a customize API.  Libraries such as this\nformat the URL behind the scenes.\nThe example below is being made to the\n","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"Dv5qkipLlF"},{"type":"link","url":"https://hydro.nationalmap.gov/arcgis/rest/services/wbd/MapServer/3","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"WBD HUC6 Feature Layer","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"iaJvVhnWei"}],"urlSource":"https://hydro.nationalmap.gov/arcgis/rest/services/wbd/MapServer/3","key":"d9AUl7xbnG"},{"type":"text","value":"\nand is being done using the already known HUC6 ids 020401 and 020402.","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"ZSp8vDAMa4"}],"key":"TD647IL1QS"},{"type":"code","lang":"python","value":"import pygeohydro\n\n# bring in HUC6 boundaries based on known IDs\ngdf = pygeohydro.WBD(\"huc6\").byids(\"huc6\", [\"020401\", \"020402\"])\n\ngdf.plot()","position":{"start":{"line":83,"column":1},"end":{"line":90,"column":1}},"key":"idNxw9A0AK"},{"type":"paragraph","position":{"start":{"line":92,"column":1},"end":{"line":96,"column":1}},"children":[{"type":"text","value":"You can also use the ","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"xYCm8Z0bKL"},{"type":"inlineCode","value":"bysql","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"cFUUG7vKwh"},{"type":"text","value":" method to send a condition to the ","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"Ga5H1HtfTT"},{"type":"emphasis","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"children":[{"type":"text","value":"where","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"pheYUwteK2"}],"key":"rWgnxlKOm0"},{"type":"text","value":" field in the\n","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"JGOVqdU44m"},{"type":"link","url":"https://hydro.nationalmap.gov/arcgis/rest/services/wbd/MapServer/3/query","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"children":[{"type":"text","value":"query","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"zzMPUDbnpa"}],"urlSource":"https://hydro.nationalmap.gov/arcgis/rest/services/wbd/MapServer/3/query","key":"ghMvHsKNGh"},{"type":"text","value":". If we\nwanted the HUC6 boundaries found only in the state of Michigan (MI), we would create a\nSQL call with ","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"HYFcUlUcb4"},{"type":"inlineCode","value":"column='value'","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"lpPcNXAB1K"},{"type":"text","value":" to query the database. (e.g. ","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"XtwIxlQxFm"},{"type":"inlineCode","value":"states='MI'","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"bmAgI3WNbp"},{"type":"text","value":"). Note the\nsingle quotes, which SQL uses in this instance.  It will not work with double quotes (\" \").","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"NKBWx9UbFa"}],"key":"tTojsPW46e"},{"type":"code","lang":"python","value":"import pygeohydro\n\n# bring in HUC boundaries found only in Michigan\ngdf = pygeohydro.WBD(\"huc6\").bysql(\"states='MI'\")\n\ngdf.plot()","position":{"start":{"line":98,"column":1},"end":{"line":105,"column":1}},"key":"FE6ihVngf8"},{"type":"heading","depth":3,"position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"children":[{"type":"inlineCode","value":"NWIS","position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"key":"c4OdAGZ1wQ"}],"identifier":"nwis","label":"NWIS","html_id":"nwis","implicit":true,"key":"gLBmaE3PpR"},{"type":"paragraph","position":{"start":{"line":109,"column":1},"end":{"line":110,"column":1}},"children":[{"type":"text","value":"This API is a member of the ","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"JqmqyofUR1"},{"type":"inlineCode","value":"hyriver","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"AVmGw5IJXD"},{"type":"text","value":" suite (as is ","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"e1n5aqyoOv"},{"type":"inlineCode","value":"pygeohydro","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"gdD2WqBkfd"},{"type":"text","value":", above).  It facilitates\nqueries to the NWIS service to obtain historical readings for stream gages.","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"EIRAmer2pq"}],"key":"QVq7hzFDDN"},{"type":"code","lang":"python","value":"from pygeohydro import NWIS\nnwis = NWIS()\nDATE_RANGE= (\"2000-01-01\", \"2010-12-31\")\n\n# returns data as pandas DataFrame\nas_dastaframe = nwis.get_streamflow('USGS-13317000', DATE_RANGE)\n\n# returns data as xarray DataSet\nas_xarray = nwis.get_streamflow('USGS-13317000', DATE_RANGE, to_xarray=True)","position":{"start":{"line":112,"column":1},"end":{"line":122,"column":1}},"key":"qpfL5xkP6t"},{"type":"heading","depth":2,"position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"strong","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"FTP","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"uyhDgDFVO8"}],"key":"PGCydqSwoK"}],"identifier":"ftp","label":"FTP","html_id":"ftp","implicit":true,"key":"JrlXHzzEXc"},{"type":"paragraph","position":{"start":{"line":126,"column":1},"end":{"line":131,"column":1}},"children":[{"type":"text","value":"FTP is often the access method for many legacy datasets. An example is bringing in\ndata from NOAAâ€™s\n","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"YkqgRLEbBr"},{"type":"link","url":"https://www.ncei.noaa.gov/access/crn/qcdatasets.html","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"children":[{"type":"text","value":"Global Climate Reference Network FTP Server","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"qaHgvtkcfe"}],"urlSource":"https://www.ncei.noaa.gov/access/crn/qcdatasets.html","key":"tpCX6KD5t0"},{"type":"text","value":".\nHere, the ","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"FiNghJVwov"},{"type":"inlineCode","value":"fsspec","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"DmBOULB33T"},{"type":"text","value":" library is used to create an FTPFileSystem instance locally that speaks to\nthe FTP server, read in a text file that contains station data using ","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"mxCfriFT1V"},{"type":"inlineCode","value":"pandas","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"v6BOQSJowd"},{"type":"text","value":", and the data is\nused to create a GeoDataFrame.","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"uH3tq1LdQO"}],"key":"PqBevQn5rk"},{"type":"code","lang":"python","value":"import geopandas as gpd\nfrom fsspec.implementations.ftp import FTPFileSystem\nimport pandas as pd\n\nfs = FTPFileSystem(\"ftp.ncei.noaa.gov\")\ndata = pd.read_table(fs.open(\"/pub/data/uscrn/products/stations.tsv\"))\n\ngdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data[\"LONGITUDE\"], data[\"LATITUDE\"]), crs=\"EPSG:4326\")\n\ngdf.plot()","position":{"start":{"line":133,"column":1},"end":{"line":144,"column":1}},"key":"oGrtaUaeE4"},{"type":"paragraph","position":{"start":{"line":146,"column":1},"end":{"line":147,"column":1}},"children":[{"type":"text","value":"Say you just wanted the daily tabular data from a single station, you could use a combination\nof ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"iTzXE6Skfx"},{"type":"inlineCode","value":"fsspec","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"hjcFX7TSKS"},{"type":"text","value":" functions, including ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"eFxnmyPMKN"},{"type":"inlineCode","value":"glob","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"yVEyyXrHSH"},{"type":"text","value":" to search for files.","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"CYJUY9uw20"}],"key":"BrQS39Fjyn"},{"type":"code","lang":"python","value":"from fsspec.implementations.ftp import FTPFileSystem\nimport pandas as pd\n\nstat_name = \"Avondale\"\n\n# instantiate FTP system\nfs = FTPFileSystem(\"ftp.ncei.noaa.gov\")\n\n# get list of all files with Avondale in name\nfile_list_glob = fs.glob(f\"/pub/data/uscrn/products/daily01/**/*{stat_name}*\")\n\n# create dataframe of data\ndf = pd.DataFrame()\n\nfor file in file_list_glob:\n    stat_data = pd.read_csv(fs.open(file), header=None, sep=\"\\t\")\n    df = pd.concat([df, stat_data])\n\n# the data is all crammed into a single column so spread it out\ndf = df[0].str.split(\" +\",expand = True)\n\ndf.head()","position":{"start":{"line":149,"column":1},"end":{"line":172,"column":1}},"key":"vjz07gkp07"}],"key":"ZFibGhzPFx"}],"key":"LatmjrUsOF"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Data Sources","url":"/essential-reading/datasources/readme","group":"Getting Started"},"next":{"title":"Data/Cloud Storage","url":"/essential-reading/datasources/data-s3","group":"Getting Started"}}},"domain":"http://localhost:3005"}