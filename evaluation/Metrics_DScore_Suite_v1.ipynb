{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Score Suite (v1) Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The suite of metrics in this notebook (table below) align with the metrics found in [Hodson et al., 2021](https://doi.org/10.1029/2021MS002681) and are custom-defined Python functions to compare modeled/simulated data against observational data over time. This notebook will briefly describe each of the below decompositions and components. The specific code to implement each is included as a function definition.  This notebook can be sourced into analysis notebooks to retrieve access to these functions. See [D-Score Usage](tutorials/stats/Usage_DScore_Suite_v1.ipynb) for an example of using these functions with a demonstration dataset. \n",
    "\n",
    "| Decomposition Name           | Metric            | Description |\n",
    "| :-----                       | :-----            |:----- |\n",
    "|Top-level Error Metric        | mse               | Mean Squared Error; error metric that is decomposed into sets of decompositions below.|\n",
    "|Bias-Variance                 | e_bias (Bias)            | Bias corresponds to error in the expected magnitude |\n",
    "|Bias-Variance                 | e_variance (Variance)    | Variance corresponds to errors in distribution and timing |\n",
    "|Bias, Distribution, Sequence  | e_bias (Bias)            | Bias corresponds to error in magnitudes |\n",
    "|Bias, Distribution, Sequence  | e_dist (Distribution)    | Distribution corresponds to distributional error independent of timing|\n",
    "|Bias, Distribution, Sequence  | e_seq (Sequence)         | Sequence related to error in ordering of values, timing|\n",
    "|Trend, Seasonality, Residual Variability  | trend        | Error related to overall trend |\n",
    "|Trend, Seasonality, Residual Variability  | seasonality  | Error related to shifts in seasonality such as phase and amplitude variation |\n",
    "|Trend, Seasonality, Residual Variability  | residual     | Remainder error, not attributed to anything in particular but still exists|\n",
    "|Seasonal                     | winter            | _Northern Hemisphere Seasons_: Dec, Jan, Feb |\n",
    "|Seasonal                     | spring            | _Northern Hemisphere Seasons_: Mar, Apr, May |\n",
    "|Seasonal                     | summer            | _Northern Hemisphere Seasons_: Jun, Jul, Aug |\n",
    "|Seasonal                     | fall              | _Northern Hemisphere Seasons_: Sep, Oct, Nov |\n",
    "|Percentile                   | low               | 5th percentile and lower |\n",
    "|Percentile                   | below_avg         | >25th percentile and <= 50th percentile |\n",
    "|Percentile                   | above_avg         | >50th percentile and <= 75th percentile |\n",
    "|Percentile                   | high              | >75th percentile |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Source: These statistics are adapted from the original functions found in <https://github.com/thodson-usgs/dscore>\n",
    "> \n",
    "> Hodson et al., 2021, Mean Squared Error, Deconstructed. Journal of Advances in Modeling Earth Systems, 13(12), https://doi.org/10.1029/2021MS002681."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "     Mean Square Error --   Compute MSE over all paired values observed (x) and simulated/modeled (x_hat)\n",
    "        .. math::\n",
    "            \\\\sum_{i=1}^{n}(x_i - \\\\hat{x}_i)^2\n",
    "\n",
    "    :return: mean square error\n",
    "    :rtype: float\n",
    "\n",
    "    NOTE: this and all functions below rely upon the obs and sim datatypes implementing \n",
    "          certain math methods on themselves.  That is, obs.sum() must be defined by \n",
    "          typeof(obs). Pandas Series and DataFrames do this, but other array_like\n",
    "          may not.\n",
    "    \"\"\"\n",
    "    e = obs - sim\n",
    "    \n",
    "    return (e**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percent Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbias(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    percent bias -- a measure of the mean tendency of simulated values to be\n",
    "    greater than or less than associated observed values.\n",
    "\n",
    "    Returns:\n",
    "        float: calculated percent bias / units = percent (i.e. 90 rather than 0.90)\n",
    "    \"\"\"\n",
    "    return 100 * (sim - obs).sum() / obs.sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Decomposition\n",
    "\n",
    "From 'Bias-Variance Trade-off'. See [Geman et al., 1992](http://dx.doi.org/10.1162/neco.1992.4.1.1) for more details. \n",
    "\n",
    "- Geman et al., 1992, Neural networks and the bias/variance dilemma. Neural Computation, 4(1), 158. http://dx.doi.org/10.1162/neco.1992.4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_bias(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Bias = square of mean error\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    e = sim - obs\n",
    "    return e.mean()**2\n",
    "\n",
    "\n",
    "def e_variance(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Variance of error\n",
    "    \n",
    "    Args:\n",
    "        obs (pd.Series - like): data representing observed values\n",
    "        sim (pd.Series - like): data representing simulated/modeled values\n",
    "\n",
    "    Returns:\n",
    "        float: variance of the error\n",
    "    \"\"\"\n",
    "    e = sim - obs\n",
    "    return e.var(ddof=0) # use the maximum likelihood estimator for the population variance; 1/n * RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Distribution-Sequence Decomposition\n",
    "- Hodson et al., 2021, Mean Squared Error, Deconstructed. Journal of Advances in Modeling Earth Systems, 13(12), https://doi.org/10.1029/2021MS002681."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_distribution_sequence(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Decomposition into bias, distribution, sequence\n",
    "\n",
    "    Args:\n",
    "        obs (pd.Series - like): data representing observed values\n",
    "        sim (pd.Series - like): data representing simulated/modeled values\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: three metrics, indexed by name\n",
    "    \"\"\"\n",
    "    \n",
    "    e = sim - obs\n",
    "    s = np.sort(sim) - np.sort(obs)\n",
    "    var_s = s.var(ddof=0) # use the maximum likelihood estimator for the population variance; 1/n * RSS\n",
    "    var_e = e.var(ddof=0) # use the maximum likelihood estimator for the population variance; 1/n * RSS\n",
    "    e_seq = var_e - var_s\n",
    "    e_dist = var_s\n",
    "    e_bias = e.mean()**2\n",
    "    return pd.Series(\n",
    "        [e_bias, e_dist, e_seq],\n",
    "        index=[\"e_bias\", \"e_dist\", \"e_seq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend, Seasonality, Residual Variability Decomposition\n",
    "The trend, seasonality, and residual variability components are not exactly orthogonal, thus the total percent error for this decomposition will sum to less than 100%. See [Cleveland et al., 1990](https://www.wessa.net/download/stl.pdf) and [Hodson et al., 2021](https://doi.org/10.1029/2021MS002681) for more information.\n",
    "\n",
    "- Cleveland et al., 1990, STL: A seasonal-trend decomposition procedure based on loess. Journal of Official Statistics, 6(1), 3-73.\n",
    "- Hodson et al., 2021, Mean Squared Error, Deconstructed. Journal of Advances in Modeling Earth Systems, 13(12), https://doi.org/10.1029/2021MS002681."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "    _SEASONAL = True\n",
    "except ImportError:\n",
    "    logging.debug(\"STL library not available.\")\n",
    "    _SEASONAL = False\n",
    "\n",
    "def stl(obs, sim):\n",
    "    \"\"\"\n",
    "    Decompose error using STL.\n",
    "\n",
    "    Seasonal and trend decomposition using Loess (STL).\n",
    "    Note that STL is not perfectly orthogonal.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Cleveland et al., 1990, STL: A seasonal-trend decomposition\n",
    "    procedure based on loess. Journal of Official Statistics, 6(1), 3-73.\n",
    "    \"\"\"\n",
    "    if not _SEASONAL:\n",
    "        logging.warning(\"STL statistics not available.\")\n",
    "        return None\n",
    "    e = sim - obs\n",
    "    res = STL(e, period=365, seasonal=9).fit()\n",
    "    E = pd.DataFrame(\n",
    "        {\n",
    "            'trend': res.trend,\n",
    "            'seasonality': res.seasonal,\n",
    "            'residual': res.resid\n",
    "        }\n",
    "    )\n",
    "    return (E**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition\n",
    "Seasonal decomposition uses Northern Hemisphere seasons as a basis, this can be customized below in the function for different seasonal divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_mse(obs, sim):\n",
    "    \"\"\"\n",
    "    Decompose error by season.\n",
    "\n",
    "    Args:\n",
    "        obs (pd.Series - like): data representing observed values\n",
    "        sim (pd.Series - like): data representing simulated/modeled values\n",
    "\n",
    "    Both obs and sim should be time-indexed, such that we can pick out months\n",
    "    from the time value.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series : mse for 4 major seasons\n",
    "    \n",
    "    NOTE: 'season' is viewed from a northern-hemisphere perspective\n",
    "    \"\"\"\n",
    "    e = sim - obs\n",
    "    idx = (e.index.month == 12) | (e.index.month <= 2) #Dec, Jan, Feb\n",
    "    winter = ((e*idx)**2).mean()\n",
    "\n",
    "    idx = (e.index.month > 2) & (e.index.month <= 5) #Mar, Apr, May\n",
    "    spring = ((e*idx)**2).mean()\n",
    "\n",
    "    idx = (e.index.month > 5) & (e.index.month <= 8) #Jun, Jul, Aug\n",
    "    summer = ((e*idx)**2).mean()\n",
    "    \n",
    "    idx = (e.index.month > 8) & (e.index.month <= 11) #Sep, Oct, Nov\n",
    "    fall = ((e*idx)**2).mean()\n",
    "\n",
    "    return pd.Series([winter, spring, summer, fall], index=['winter', 'spring', 'summer', 'fall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Decomposition\n",
    "MSE is decomposed by quantile range:\n",
    "\n",
    "| Q from | Q to | Label |\n",
    "| :----- | :----- | :------ |\n",
    "| 0.00 | 0.25 | Low |\n",
    "| 0.25 | 0.50 | Below-Average |\n",
    "| 0.50 | 0.75 | Above-Average |\n",
    "| 0.75 | 1.00 | High | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_mse(obs, sim):\n",
    "    \"\"\"\n",
    "    Decomposes MSE by quantile rangess 0.00-0.25; 0.25-0.5; 0.5-0.75; 0.75-1.00\n",
    "\n",
    "    Args:\n",
    "        obs (pd.Series - like  ): series of observed values\n",
    "        sim (_type_): series of simulated/modeled values\n",
    "    Both share a common index\n",
    "\n",
    "    Returns:\n",
    "        pd.Series : decomposed MSE, one value per quantile range\n",
    "    \"\"\"\n",
    "    breaks=[0, 0.25, 0.5, 0.75, 1]\n",
    "    labels=['low', 'below_avg', 'above_avg', 'high']\n",
    "    e = sim - obs\n",
    "    scores = []\n",
    "    ranks = obs.rank(method='first')\n",
    "    quants = pd.qcut(ranks, q=breaks)\n",
    "    for i in range(len(breaks) - 1):\n",
    "        quant = e * (quants == quants.cat.categories[i])  # select quantile\n",
    "        mse_q = ((quant)**2).mean()\n",
    "        scores.append(mse_q)\n",
    "    return pd.Series(scores, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Function - ILAMB Scoring\n",
    "- Collier et al., 2018, The International Land Model Benchmarking (ILAMB) system: Design, theory, and implementation. Journal of Advances in Modeling Earth Systems, 10(11), http://dx.doi.org/10.1029/2018ms001354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(e, a=1.0):\n",
    "    \"\"\"\n",
    "    Scores an error\n",
    "\n",
    "    Exponential scoring function that maps MSE to the unit interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : float\n",
    "        Positive tuning parameter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Collier et al., 2018, The International Land Model Benchmarking\n",
    "    (ILAMB) system: Design, theory, and implementation. Journal of Advances\n",
    "    in Modeling Earth Systems, 10(11), http://dx.doi.org/10.1029/2018ms001354\n",
    "    \"\"\"\n",
    "    if a <= 0.0:\n",
    "        raise ValueError(\"Tuning parameter must be a positive float\")\n",
    "    return np.exp(-1 * a * e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScoreCard Visualizations\n",
    "\n",
    "These routines help with formatting scorecards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ilamb_card_II(df, ax=None, clim=(0,100), cmap='RdYlBu'):\n",
    "    axs = ax or plt.gca()\n",
    "    try:\n",
    "        axs.set_xlabel(df.name)  # note that name is not a standard dataframe attribute.\n",
    "    except NameError:\n",
    "        pass # Don't set xaxis label name\n",
    "        \n",
    "    axs.set_ylabel(\"Component\")\n",
    "    axs.set_yticks(np.arange(len(df.index)), labels=df.index, fontsize=6)\n",
    "    axs.yaxis.set_tick_params(length=0, which='minor')\n",
    "\n",
    "    axs.set_xticks(np.arange(len(df.columns)), labels=df.columns, fontsize=6, rotation=90, ha='center', va='bottom')\n",
    "    axs.xaxis.tick_top()\n",
    "    axs.xaxis.set_tick_params(length=0)\n",
    "    axs.xaxis.set_label_position('top') \n",
    "\n",
    "    # Thick black lines between decompositions\n",
    "    axs.axhline(y=0.5, color='k') #betwen cells 0 and 1\n",
    "    axs.axhline(y=3.5, color='k') # between 3 and 4 \n",
    "    axs.axhline(y=6.5, color='k') # between 6 and 7 \n",
    "    axs.axhline(y=10.5, color='k') # between 9 and 10\n",
    "\n",
    "    im = axs.imshow(df, cmap=cmap, vmin=clim[0], vmax=clim[1], alpha=0.80)\n",
    "    cbar = axs.figure.colorbar(im, ax=axs, location='bottom', ticks=[0, 50, 100], ticklocation='bottom', pad=0.05, fraction=0.15, shrink=0.5)\n",
    "    cbar.ax.tick_params(labelsize=4, width=0.2, length=2, pad=1, labelbottom=True)\n",
    "    cbar.outline.set_linewidth(0.2)\n",
    "\n",
    "    ## Annotates each cell...\n",
    "    txtattrs = dict(ha=\"center\", va=\"center\", fontsize=5)\n",
    "    i=0\n",
    "    for col in df.columns:\n",
    "        j=0\n",
    "        for row in df.index:\n",
    "            text = im.axes.text(i, j, df[col][row], **txtattrs)\n",
    "            j+=1\n",
    "        i+=1\n",
    "    \n",
    "    ## Offset minor gridlines.... paint them white. \n",
    "    axs.set_yticks(np.arange(len(df.index)+1)-.5, minor=True)\n",
    "    axs.set_xticks(np.arange(len(df.columns)+1)-.5, minor=True)\n",
    "    axs.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=0.75)\n",
    "    \n",
    "    return axs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7ebce313f85fb1ac8949e834c83f371584cb2422d845bf1570c1220fdedc716"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
