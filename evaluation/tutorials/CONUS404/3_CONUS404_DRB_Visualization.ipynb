{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualizing CONUS404 and reference data \n",
    " \n",
    " Author: Hannah Podzorski, USGS\n",
    " \n",
    "<img src='../../../doc/assets/Eval_Viz.svg' width=600>\n",
    "\n",
    "The purpose of this notebook is to visualize both gridded and tabular data sets. This notebook uses [`HoloViz`](https://holoviz.org/) and [`Panel`](https://panel.holoviz.org/index.html) to create interactive visuals that allow you to compare two datasets. `HoloViz` is designed to help reduce redundancy by allowing components to be used multiple times between charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the steps this notebook follows:\n",
    "\n",
    "- Step 0: Import Libraries\n",
    "- Step 1: Accessing the Data\n",
    "- Step 2: Visualize and Compare Gridded Data\n",
    "- Step 3: Visualize and Compare Tabular Data\n",
    "- Step 4: Examine Comparisons\n",
    "\n",
    "## **Step 0: Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# library imports\n",
    "import os\n",
    "import cf_xarray\n",
    "import dask\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import fsspec \n",
    "import geopandas as gpd\n",
    "import hvplot.xarray\n",
    "import intake\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygeohydro\n",
    "import sparse \n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n",
    "import panel as pn\n",
    "import datetime as dt\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import param\n",
    "import hvplot.pandas\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "pn.extension(loading_indicator = True, defer_load = True)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Accessing the Data**\n",
    "\n",
    "First, we will instantiate a connection to the HyTEST intake catalog YML and then we will access the forcings tutorial sub catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to HyTEST catalog\n",
    "url = 'https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml'\n",
    "cat = intake.open_catalog(url)\n",
    "\n",
    "# access tutorial catalog\n",
    "conus404_drb_cat = cat[\"conus404-drb-eval-tutorial-catalog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a description of each data set and what type of data it contains (gridded or tabular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data sets names and descriptions\n",
    "for item in list(conus404_drb_cat):\n",
    "    descr = conus404_drb_cat[item].description\n",
    "    if conus404_drb_cat[item].metadata.get(\"gridded\") == True:\n",
    "        data_type = \"Gridded\"\n",
    "    else:\n",
    "        data_type = \"Tabular\"\n",
    "    print(f\"{item} ({data_type}): {descr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we may want to start a dask client using an appropriate Dask Cluster. This is an optional step, but can speed up data loading significantly, especially when accessing data from the cloud.\n",
    "\n",
    "Setup your client on your local PC or on HPC like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing Dask cluster\n",
    "if \"client\" in locals():\n",
    "    print(\"Shutting down existing Dask cluster.\")\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "print(f\"The link to the Dask dashboard is {client.dashboard_link}. If on HPC, this may not be available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are brought into the notebook using Dask through a couple of steps. First, the entry (prism-drb-OSN) in the catalog (conus404_drb_cat) is indexed and the method `to_dask` will automatically load the data from the catalog entry. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of how data is loaded using dask\n",
    "prism_drb = conus404_drb_cat['prism-drb-OSN'].to_dask()\n",
    "prism_drb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Visualize and Compare Gridded Data**\n",
    "\n",
    "Now we're going to create interactive maps of two different gridded datasets. The two different datasets we will be using are the CONUS404 Delaware River Basin subset (_'conus404-drb-OSN'_) and the PRISM Delaware River Basin subset (_'prism-drb-OSN'_).\n",
    "\n",
    "Let's start by loading in our two datasets and combining them into a list. Note that the timesteps in these datasets are the same (monthly). However, they have different periods of record. We will use the first time point for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridded datasets\n",
    "gridded_options = ['conus404-drb-OSN', 'prism-drb-OSN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in selected data\n",
    "def load_data(data_sources):\n",
    "    _data = conus404_drb_cat[data_sources].to_dask()\n",
    "    date = _data.time.min().values # select only the minimum time in the dataset\n",
    "    return _data.sel(time = date)\n",
    "\n",
    "def multi_load(data_source):\n",
    "    _data = []\n",
    "    for data in data_source:\n",
    "        _data.append(load_data(data))\n",
    "    return _data\n",
    "\n",
    "data = multi_load(gridded_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start creating the components of our panel app. We need to create a selector that will allow us to select the variable we would like to visualize in our maps. First, we need to determine which variables are present in both datasets. Then we can create a widget that will allow us to change between those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of variables that are in both data sets\n",
    "def get_var(data): \n",
    "    _var = [value for value in data[0].data_vars if value in data[1].data_vars]\n",
    "    return  _var\n",
    "\n",
    "var = get_var(data) \n",
    "\n",
    "# Create variable selector\n",
    "var_selector = pn.widgets.Select(\n",
    "    name = \"Select Variable\",\n",
    "    description = \"Only variables available in both data sources are shown.\",\n",
    "    options = var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a selector that will allow us to change the base map for our interactive maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of base map options.\n",
    "base_map_options = {\n",
    "    'OpenStreetMap': gv.tile_sources.OSM,\n",
    "    'ESRI Imagery': gv.tile_sources.EsriImagery,\n",
    "    'ESRI World Street Map': gv.tile_sources.EsriWorldStreetMap,\n",
    "}\n",
    "\n",
    "# Create selector for base map\n",
    "map_selector = pn.widgets.Select(\n",
    "    name=\"Select a Base Map\",\n",
    "    options=list(base_map_options.keys()),\n",
    "    value = 'OpenStreetMap'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to create a function that we can use to map our data. Below is a simple function that will create a map based on the dataset, variable, and basemap provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gridded data on map\n",
    "def map(data, var, base_map):\n",
    "    _base_map = base_map_options.get(base_map)\n",
    "    _map = data[var].hvplot(\n",
    "        x = 'x', y = 'y', geo = True, \n",
    "        rasterize = True, tiles = _base_map) \n",
    "    return _map\n",
    "pn.rx(map)(data[0], var_selector, map_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put all our components together in a panel app. We will do this by creating a function that will create our two maps and put them into a panel layout. We will then use the function `pn.rx()` to bind that function to its inputs, including the reactive inputs that we use to change variables and base maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Panel App Layout\n",
    "def layout(data, source, var, base_map):\n",
    "    map_0 = map(data[0], var, base_map)\n",
    "    map_1 = map(data[1], var, base_map)\n",
    "\n",
    "    layout = pn.Row(pn.Column(pn.pane.Markdown(f\"## *{source[0]}*\"), map_0), \n",
    "                    pn.Column(pn.pane.Markdown(f\"## *{source[1]}*\"), map_1))\n",
    "    return layout\n",
    "\n",
    "map_layout = pn.rx(layout)(data, gridded_options, var_selector, map_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_app = pn.Column(\"# Gridded Data Comparison\", map_layout) # add an app title\n",
    "gridded_app.servable() # display components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we displayed the app within this notebook, but you can also use the function `.show()` to open the app in a browser. Run the code below if you would like to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridded_app.show('CONUS404 Gridded Dashboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Visualize and Compare Tabular Data**\n",
    "\n",
    "Now we're going to create interactive maps and timeseries plots of two different tabular datasets. The two different data sets we will use are the Climate Reference Network subset ('crn-drb-OSN') and the Historical Climate Network subset ('hcn-drb-OSN'). \n",
    "\n",
    "Let's start by loading in our two data sets and combining them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset gridded data sets\n",
    "tabular_options = ['crn-drb-OSN', 'hcn-drb-OSN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To preview CRN data or HCN data tabular data, uncomment each line below.\n",
    "#print('CRN', conus404_drb_cat['crn-drb-OSN'].read().head())\n",
    "#print('HCN', conus404_drb_cat['hcn-drb-OSN'].read().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_tabular(data_sources):\n",
    "    _data = conus404_drb_cat[data_sources].read()\n",
    "    _data[[\"LATITUDE\", \"LONGITUDE\"]] = _data[[\"LATITUDE\", \"LONGITUDE\"]].astype(float)\n",
    "    return _data\n",
    "\n",
    "def multi_load(data_source):\n",
    "    _data = []\n",
    "    for data in data_source:\n",
    "        _data.append(load_data_tabular(data))\n",
    "    return _data\n",
    "\n",
    "data = multi_load(tabular_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get started on our components for our panel app. This will be very similar to what we did for the gridded data. We will create a widget to select the variable we would like to visualize and the base map we would like to use. In addition, we will also need widgets to select the stations we would like to view on our timeseries plot from each of the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create selector of variables\n",
    "var_selector_tabular = pn.widgets.Select(\n",
    "    name = \"Select Variable\",\n",
    "    options = ['PREC_ACC_NC', 'TK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add selector for base map\n",
    "base_map_options = {\n",
    "    'OpenStreetMap': gv.tile_sources.OSM,\n",
    "    'ESRI Imagery': gv.tile_sources.EsriImagery,\n",
    "    'ESRI World Street Map': gv.tile_sources.EsriWorldStreetMap,\n",
    "}\n",
    "\n",
    "map_selector_tabular = pn.widgets.Select(\n",
    "    description=\"Use to select Base Map\",\n",
    "    name=\"Select a Base Map\",\n",
    "    options=list(base_map_options.keys()),\n",
    "    value = 'OpenStreetMap'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create selectors for each dataset stations\n",
    "ID_selector_0 = pn.widgets.Select(\n",
    "    name = \"Select a Climate Reference Network Station (blue)\",\n",
    "    options = list(data[0][\"ID\"].unique())) # pull out unique stations from the crn dataset\n",
    "\n",
    "ID_selector_1 = pn.widgets.Select(\n",
    "    name = \"Select a Historical Climate Network Station (red)\",\n",
    "    options = list(data[1][\"ID\"].unique())) # pull out unique stations from the hcn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need functions that will plot our maps and our timeseries comparisons based on our selected variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map of the CRN and HCN locations so the proximity of the measurement locations can be examined in relation to the timeseries.\n",
    "def create_map(data, base_map, ID_0, ID_1):\n",
    "    # Combine the data from both datasets\n",
    "    combined_data = pd.concat(data, ignore_index=True)\n",
    "\n",
    "    # Create the base map layer\n",
    "    base_map_layer = base_map_options.get(base_map)\n",
    "\n",
    "    # Create some larger bounds around lat/long locations\n",
    "    xlim = (combined_data['LONGITUDE'].min()-(0.5), combined_data['LONGITUDE'].max()+(0.5))\n",
    "    ylim = (combined_data['LATITUDE'].min()-(0.5), combined_data['LATITUDE'].max()+(0.5))\n",
    "\n",
    "    # Create points for all locations in black\n",
    "    all_points = combined_data.hvplot.points(\n",
    "        x='LONGITUDE', y='LATITUDE',\n",
    "        geo=True, tiles=base_map_layer,\n",
    "        color='black', size=50, hover_cols=['ID'],\n",
    "        xlim = xlim, ylim = ylim,\n",
    "        frame_width=150\n",
    "    )\n",
    "\n",
    "    # Highlight selected points\n",
    "    highlighted_points_0 = combined_data[combined_data[\"ID\"] == ID_0].hvplot.points(\n",
    "        x='LONGITUDE', y='LATITUDE',\n",
    "        geo=True, color='blue', size=100, hover_cols=['ID'],\n",
    "        xlim = xlim, ylim = ylim\n",
    "    ) if ID_0 else hv.Points([])\n",
    "\n",
    "    highlighted_points_1 = combined_data[combined_data[\"ID\"] == ID_1].hvplot.points(\n",
    "        x='LONGITUDE', y='LATITUDE',\n",
    "        geo=True, color='red', size=100, hover_cols=['ID'],\n",
    "        xlim = xlim, ylim = ylim\n",
    "    ) if ID_1 else hv.Points([])\n",
    "\n",
    "    # Combine all layers\n",
    "    combined_map = base_map_layer * all_points * highlighted_points_0 * highlighted_points_1\n",
    "    return combined_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries plots\n",
    "def timeseries(data, ID_0, ID_1, var):\n",
    "    _data0 = data[0][data[0][\"ID\"] == ID_0]\n",
    "    _data1 = data[1][data[1][\"ID\"] == ID_1]\n",
    "    _data = pd.concat([_data0, _data1], ignore_index=True)\n",
    "    plot = _data.hvplot.line(x = \"DATE\", y = var, by = 'ID')\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put everything together in our panel app. Once again, we will create a function that creates the layout for our panel app and then bind it to the reactive variables using the `pn.rx()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Layout\n",
    "def plot_layout(source, data, var, base_map, ID_0, ID_1):\n",
    "    # map\n",
    "    map_0 = create_map(data, base_map, ID_0, ID_1)\n",
    "    \n",
    "    # timeseries\n",
    "    plot = timeseries(data, ID_0, ID_1, var)\n",
    "\n",
    "    # identify rows in layout\n",
    "    row_1 = map_0\n",
    "    row_2 = pn.Row(plot)\n",
    "    \n",
    "    return pn.Column(row_1, row_2)\n",
    "\n",
    "map_layout = pn.rx(plot_layout)(tabular_options, data, var_selector_tabular, map_selector_tabular, ID_selector_0, ID_selector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_app = pn.Column(\"# Tabular Data Comparison\", map_layout) # add a title\n",
    "tabular_app.servable() # display components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we displayed the app within this notebook, but you can also use the function `.show()` to open the app in a browser. Run the code below if you would like to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabular_app.show('CONUS404 Tabular Dashboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: Examine Comparisons**\n",
    "\n",
    "There are various tabular datasets with the evaluation results that can be explored. For this example, we will examine how the station data compares to CONUS404."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine CONUS404 comparisons to CRN & HCN stations\n",
    "There is only one Climate Reference Network station within the Delaware River Basin (\"Avondale\") that we can compare to CONUS404, meanwhile there are 14 Hydrologic Climate Network stations that we can compare to CONUS404. Let's combine the evaluation results of the station data and create a bar graph that has an option to select the statistic of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature & Precipitation (CONUS404 to HCN) Evaluation Results\n",
    "hcn_eval = conus404_drb_cat['c404-hcn-drb-desc-stats-OSN'].to_dask()\n",
    "\n",
    "# This will load the entire DataFrame into memory\n",
    "hcn_eval = hcn_eval.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature & Precipitation (CONUS404 to PRISM) Evaluation Results\n",
    "crn_eval = conus404_drb_cat['c404-crn-drb-desc-stats-OSN'].to_dask()\n",
    "\n",
    "# This will load the entire DataFrame into memory\n",
    "crn_eval = crn_eval.compute()\n",
    "\n",
    "# Add ID on dataframe\n",
    "crn_eval['ID'] = 'Avondale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim columns that are consistent between the two datasets\n",
    "columns = ['ID','stat','PREC_ACC_NC_c404','TK_c404']\n",
    "crn_eval = crn_eval[columns]\n",
    "hcn_eval = hcn_eval[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine the comparative statistics from HCN and CRN compared to CONUS404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "df = pd.concat([crn_eval, hcn_eval], ignore_index=True)\n",
    "\n",
    "# Remove summary statistics\n",
    "df = df[~df['stat'].isin(['annual_mean', 'mean', 'median','stdev'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our interactive bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a selector for the statistics\n",
    "stat_selector = pn.widgets.Select(name='Select Statistic', options=df['stat'].unique().tolist())\n",
    "\n",
    "# Create a selector for the variable (precipitation or temperature)\n",
    "var_selector = pn.widgets.Select(name='Select Variable', options=['PREC_ACC_NC_c404', 'TK_c404'])\n",
    "\n",
    "# Function to update the bar graph based on the selected statistic\n",
    "def update_bar_graph(stat, var_type):\n",
    "    filt_df = df[df['stat'] == stat]\n",
    "    return filt_df.hvplot.bar(x='ID', y=var_type, \n",
    "                              title=f'{var_type}', \n",
    "                              xlabel='ID', ylabel = stat,\n",
    "                              rot = 45)\n",
    "\n",
    "# Create a Panel with the selector and the bar graph\n",
    "interactive_plot = pn.bind(update_bar_graph, stat=stat_selector, var_type = var_selector)\n",
    "\n",
    "# Layout\n",
    "layout = pn.Column(stat_selector, var_selector, interactive_plot)\n",
    "\n",
    "# Serve the Panel\n",
    "eval_app = pn.Column(\"# CONUS404 versus station data\", layout)\n",
    "eval_app.servable() # display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
