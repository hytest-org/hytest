{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23cabac-5a21-48d0-b7b1-e36671f0a718",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "## Streamflow Benchmarking Tutorial\n",
    "\n",
    "This notebook is an example of how a HyTEST user may examine some streamflow benchmark results from a hydrologic model. \n",
    "\n",
    "Here, we are viewing daily streamflow benchmark results from the [example analysis](02_Analysis_StdSuite.ipynb) \n",
    "of [National Water Model Retrospective version 2.1](https://registry.opendata.aws/nwm-archive/), \n",
    "forced with AORC, at streamflow benchmark locations (\"cobalt gages\" [Foks et al., 2022](https://www.sciencebase.gov/catalog/item/6181ac65d34e9f2789e44897)).\n",
    "\n",
    "Two different benchmark results are examined:\n",
    "* the standard statistical suite results ('standard suite')\n",
    "([Towler et al., 2022](https://www.sciencebase.gov/catalog/item/62336af9d34ec9f19eeb48fd)) \n",
    "* decomposition statistical suite results ('d-score') ([Hodson et al., 2022](https://www.sciencebase.gov/catalog/item/61d4c9e9d34ed79293fe91b4))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7799528-70eb-43ef-92bf-dc76b731ed79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 0: Load Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df078209-e4e8-4429-82b4-8ac491a36686",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import holoviews as hv\n",
    "    import hvplot.pandas\n",
    "    import panel as pn\n",
    "    from geoviews import tile_sources as gvts\n",
    "    from holoviews import opts\n",
    "except ImportError:\n",
    "    print(\"A required library could not be found. \")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9ab7b",
   "metadata": {},
   "source": [
    "## Step 1: Load Domain Data\n",
    "\n",
    "Loading the dataset representing the 'cobalt' gages. This includes location and other metadata about each streamflow gage. We will need this extra metadata to get lat/lon and other characteristics of the gage locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3098bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobalt = pd.read_csv(\n",
    "    'https://www.sciencebase.gov/catalog/file/get/6181ac65d34e9f2789e44897?f=__disk__22%2F1a%2Fd2%2F221ad2fe9d95de17731ad35d0fc6b417a4b53ee1',\n",
    "    dtype={'site_no':str, 'huc_cd':str, 'reachcode':str, 'comid':str, 'gagesII_class':str, 'aggecoregion': str}, \n",
    "    index_col='site_no')\n",
    "# Re-format the gage_id/site_no string value.  ex:   \"1000000\"  ==> \"USGS-1000000\"\n",
    "cobalt.rename(index=lambda x: f'USGS-{x}', inplace=True)\n",
    "cobalt.rename(columns={'dec_lat_va':'Lat', 'dec_long_va':'Lon'} , inplace=True)\n",
    "print(f\"{len(cobalt.index)} gages in this benchmark\")\n",
    "cobalt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980fdd0b-b065-4047-883b-d70cb5b71634",
   "metadata": {},
   "source": [
    "## Step 2: Load results from the analysis notebooks\n",
    "\n",
    "This table is the collection of evaluation metrics comparing observed vs. modeled streamflow of the cobalt gages. This data is the result\n",
    "of the [Standard Suite Analysis Notebook](02_Analysis_StdSuite.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(r'./Standard_streamflow_example.csv', dtype={'site_no':str} ).set_index('site_no', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge benchmarks with cobalt data to form a single table, indexed by site_no\n",
    "metrics = results.columns.tolist()[1:] #list of columns, EXCEPT the first column (site_no)\n",
    "results = results.merge(\n",
    "    cobalt,                # Table to merge with NWM\n",
    "    how='left',            # left join preserves only records which have an index in modeled data dataframe.\n",
    "    left_index=True,        \n",
    "    right_index=True\n",
    "    )\n",
    "# The effect of the left join is that if a cobalt gage does not have a computed benchmark in NWM, \n",
    "# (e.g. due to error in the analysis process), it is dropped from the visualization set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dda23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Visualize NWM Benchmark Results\n",
    "A quick look at the joined data table shows that we have a collection of metrics, and the associated metadata, \n",
    "all indexed by the `site_id`.  This table is sortable by column -- you can scroll and select to explore the \n",
    "raw result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ca799",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hvplot.table(\n",
    "    columns=['site_no', 'drain_sqkm','KGE', 'NSE','logNSE','pearson','spearman','rSD','pbias','pBiasFMS','pBiasFHV','pBiasFLV','complete_yrs','n_days'], \n",
    "    sortable=True, \n",
    "    selectable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea9e9f-5184-42ae-92d9-ee08985048e7",
   "metadata": {},
   "source": [
    "### Step 3a: Benchmark Results Mapped Over the Spatial Extent of the Conterminous United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23176bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_select = pn.widgets.Select(name='Metric', options=metrics, value='pearson')\n",
    "base_map_select = pn.widgets.Select(name='Basemap:', \n",
    "                                    options=list(gvts.tile_sources.keys()), \n",
    "                                    value='OSM')\n",
    "\n",
    "@pn.depends(var=var_select, base_map=base_map_select)\n",
    "def plot(var, base_map):\n",
    "    return results.hvplot.points(x='Lon', y='Lat', color=var, cmap='turbo_r', geo=True, tiles=base_map)\n",
    "\n",
    "col = pn.Column(var_select, base_map_select, plot)\n",
    "col.servable('Hydro Assessment Tool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db833b-54d9-4861-8799-ed82eb7c1fa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3b: Boxplots\n",
    "Grouped by \n",
    "* Gages-II classification, \n",
    "* HUC02 group, or \n",
    "* Aggregated Ecoregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7db9b8-9adc-4f76-bf1a-5067fbe56856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which columns are metrics in the widget and which ones are groups\n",
    "var_select = pn.widgets.Select(name='Metric', \n",
    "        options=metrics, \n",
    "        value='pearson')\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "        options=['huc02', 'gagesII_class', 'aggecoregion'], \n",
    "        value='aggecoregion')\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "def plot(var, group):\n",
    "        # local scope func to calc summary stats using var/group\n",
    "        # build tooltip using the result. \n",
    "        # pandas will compute with groupby(). \n",
    "    return results.hvplot.box(y = var, by = group, height=400, width=800, legend=False)\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('Benchmark Box Plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4be5e-85b2-4af1-a18d-beadd727f1c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3c: Histograms \n",
    "Grouped by \n",
    "* Gages-II classification, \n",
    "* HUC02 group, or \n",
    "* Aggregated Ecoregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e7e2d-ccd7-4ea7-9689-9d4516932fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_select = pn.widgets.Select(name='Metric', \n",
    "        options=metrics, \n",
    "        value='pearson'\n",
    "    )\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "        options=['huc02', 'gagesII_class', 'aggecoregion'], \n",
    "        value='aggecoregion'\n",
    "    )\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "def plot(var, group):\n",
    "    return results.hvplot.hist(var, group, subplots=True, width=400, bins = 500, legend='top')\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('Benchmark Histograms')\n",
    "# TODO: Constrain to fixed width for rendering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5a0a3-a779-4c38-afc8-fb2e806e2e14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3d: Metric by Latitude & Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e460ca4-f06d-4e29-a2b8-bfe312400f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_select = pn.widgets.Select(name='Metric', options=metrics, \n",
    "                               value='pearson')\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "                                    options=['Lon', 'Lat'], \n",
    "                                    value='Lon')\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "def plot(var, group):\n",
    "    return results.hvplot.scatter(x=group, y=var, height=400, width = 500, legend='top', hover_cols=[\"site_no\",\"Lat\",\"Lon\"])\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('Lat/Lon Scatter Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fbbcde-f929-4043-a515-d8fe3cbe037f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3e: Metric v. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ef2d7-d432-4dc5-9ee3-670ceade3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_select = pn.widgets.Select(name='Metric', options=metrics, \n",
    "                               value='pearson')\n",
    "\n",
    "var2_select = pn.widgets.Select(name='Metric:', \n",
    "                                    options=metrics, \n",
    "                                    value='spearman')\n",
    "\n",
    "@pn.depends(var_select, var2_select)\n",
    "\n",
    "def plot(var, var2):\n",
    "    return results.hvplot.scatter(x = var, y = var2, height=400, width = 500, legend='top', hover_cols=['site_no','Lat', 'Lon'])\n",
    "\n",
    "col = pn.Column(var_select, var2_select, plot)\n",
    "col.servable('Metric v Metric Scatter Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78750cd",
   "metadata": {},
   "source": [
    "------\n",
    "## Step 4: Visualize D-Score Analysis Results\n",
    "\n",
    "The above steps are repeated for the DScore analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8790134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is loaded \n",
    "DScore = pd.read_csv(r'./DScore_streamflow_example.csv', dtype={'site_no':str} ).set_index('site_no', drop=False)\n",
    "\n",
    "# Merge benchmarks with cobalt data to form a single table, indexed by site_no\n",
    "metrics = DScore.columns.tolist()[1:] \n",
    "DScore = DScore.merge(\n",
    "    cobalt, \n",
    "    how='left',\n",
    "    left_index=True, \n",
    "    right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d06e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data table\n",
    "cols = ['site_no']\n",
    "cols.extend(metrics)\n",
    "DScore.hvplot.table(\n",
    "    columns=cols, \n",
    "    sortable=True, \n",
    "    selectable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b681d-a56a-406d-a743-48bf78d6666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score components as a percent of the total error (mse)\n",
    "\n",
    "# Select only numeric columns for division (also first 15 columns)\n",
    "numeric_columns = DScore.iloc[:, :16].select_dtypes(include='number')\n",
    "\n",
    "# Perform the division by 'mse'\n",
    "# Here we ensure to divide each numeric column by the 'mse' column\n",
    "percentage_card = (numeric_columns.div(DScore['mse'], axis=0) * 100).round().astype(int)\n",
    "\n",
    "# Merge back the metadata for mapping/etc\n",
    "percentage_card = percentage_card.merge(\n",
    "    cobalt, \n",
    "    how='left',\n",
    "    left_index=True, \n",
    "    right_index=True\n",
    "    )\n",
    "\n",
    "# Set the name for the DataFrame\n",
    "percentage_card.name = \"Percent\"\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"\\nPercentage Card DataFrame:\")\n",
    "print(percentage_card[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc1e94-8664-442e-945c-79fab7ee6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that a scorecard such as this is typically applied to a composite of d-score metrics\n",
    "# computed for many gages (i.e., average of each component over all streamgages in our analysis).\n",
    "\n",
    "# Calculate the average scores per column (components)\n",
    "average_scores = percentage_card.iloc[:, :15].mean()\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3531f4-d102-4c44-95f4-b449bc4d322f",
   "metadata": {},
   "source": [
    "## Map dscore components\n",
    "Using the percentage of the MSE that a particular component is comprised of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "var_select = pn.widgets.Select(name='Metric', options=metrics, value='mse')\n",
    "base_map_select = pn.widgets.Select(name='Basemap:', \n",
    "                                    options=list(gvts.tile_sources.keys()), \n",
    "                                    value='OSM')\n",
    "\n",
    "@pn.depends(var=var_select, base_map=base_map_select)\n",
    "def plot(var, base_map):\n",
    "    return percentage_card.hvplot.points(x='Lon', y='Lat', color=var, cmap='turbo_r', geo=True, tiles=base_map)\n",
    "\n",
    "col = pn.Column(var_select, base_map_select, plot)\n",
    "col.servable('Hydro Assessment Tool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots\n",
    "var_select = pn.widgets.Select(name='Metric', \n",
    "        options=metrics, \n",
    "        value='mse')\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "        options=['huc02', 'gagesII_class', 'aggecoregion'], \n",
    "        value='aggecoregion')\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "def plot(var, group):\n",
    "    return percentage_card.hvplot.box(y = var, by = group, height=400, width=800, legend=False)\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('DScore Benchmark Box Plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6842be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric vs metric\n",
    "var_select = pn.widgets.Select(name='Metric', options=metrics, \n",
    "                               value='mse')\n",
    "\n",
    "var2_select = pn.widgets.Select(name='Metric:', \n",
    "                                    options=metrics, \n",
    "                                    value='high')\n",
    "\n",
    "@pn.depends(var_select, var2_select)\n",
    "\n",
    "def plot(var, var2):\n",
    "    return percentage_card.hvplot.scatter(x = var, y = var2, height=400, width = 500, legend='top', hover_cols=['site_no','Lat', 'Lon'])\n",
    "\n",
    "col = pn.Column(var_select, var2_select, plot)\n",
    "col.servable('Metric v Metric Scatter Plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-pangeo",
   "language": "python",
   "name": "conda-env-global-global-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7ebce313f85fb1ac8949e834c83f371584cb2422d845bf1570c1220fdedc716"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
