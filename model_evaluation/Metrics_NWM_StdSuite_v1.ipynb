{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NWM 'Standard Suite (v1)' Metrics\n",
    "\n",
    "These are custom-defined Python functions to calculate metrics against time-series data. \n",
    "\n",
    "These statistics adapted from the originals in <https://github.com/USGS-python/hytest-evaluation-workflows/blob/main/gallery/streamflow/02_nwm_benchmark_analysis.ipynb> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Metrics:\n",
    "This suite of metrics describes the NWM benchmark:\n",
    "\n",
    "| Metric | Reference |\n",
    "| ----- | ----- |\n",
    "| Nash-Sutcliffe efficiency (NSE)     | Nash, J. E., & Sutcliffe, J. V. (1970). River flow forecasting through conceptual models part I—A discussion of principles. Journal of hydrology, 10(3), 282-290. https://www.sciencedirect.com/science/article/pii/0022169470902556?via%3Dihub\n",
    "| Kling-Gupta efficiency (KGE)        | Gupta, H. V., Kling, H., Yilmaz, K. K., & Martinez, G. F. (2009).  Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling. Journal of hydrology, 377(1-2), 80-91. https://www.sciencedirect.com/science/article/pii/S0022169409004843 |\n",
    "| logNSE                              | Oudin, L., Andréassian, V., Mathevet, T., Perrin, C., & Michel, C. (2006). Dynamic averaging of rainfall‐runoff model simulations from complementary model parameterizations. Water Resources  Research, 42(7).|\n",
    "| percent bias                        | A measure of the mean tendency of simulated values to be greater or less than associated observed values, units of percent |\n",
    "| ratio of standard deviation         | standard deviation of simulated values divided by the standard deviation of observed values |\n",
    "| Pearson Correlation                 | K. Pearson (1896, 1900, 1920)                                       |\n",
    "| Spearman Correlation                | Charles Spearman (1904, 1910)                                       |\n",
    "| percent bias in midsegment slope of the flow-duration curve (FDC) between Q20-Q70 | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC low-segment volume (Q0-Q30) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC high-segment volume (Q98-Q100) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "\n",
    "\n",
    "This notebook will briefly describe each of the above metrics, and show some results using sample data. \n",
    "The specific code to implement each metric is included.  This notebook can be sourced into analysis notebooks\n",
    "to get access to these functions natively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nash-Sutcliffe efficiency (NSE)\n",
    "\n",
    "Nash, J. E., & Sutcliffe, J. V. (1970). River flow forecasting through conceptual models part I—A discussion of principles. Journal of hydrology, 10(3), 282-290. https://www.sciencedirect.com/science/article/pii/0022169470902556?via%3Dihub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used by NSE and others... \n",
    "def MSE(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Mean Square Error --   Compute MSE over all paired values obs (x) and sim (x_hat)\n",
    "        .. math::\n",
    "            \\displaystyle\\sum_{i=1}^{n}(x_i - \\hat{x}_i)^2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Mean square error\n",
    "    \"\"\"\n",
    "    err = obs - sim\n",
    "    return np.mean(err**2)\n",
    "\n",
    "def NSE(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Nash-Sutcliffe efficiency (NSE)\n",
    "\n",
    "    Returns:\n",
    "        float: calculated NSE\n",
    "    \"\"\"\n",
    "    return 1 - (MSE(obs, sim) / np.var(obs, ddof=0))\n",
    "    # See NOTE re:  ddof "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special note on NSE &amp; variance** &mdash; A component within the calculation of NSE is _variance_ computed over the \n",
    "observed values. Different python libraries calculated this in different ways, so some of the details matter\n",
    "when calculating.  In particular, `numpy` assumes that `ddof` (Delta Degrees of Freedom) \n",
    "is [zero](https://numpy.org/doc/stable/reference/generated/numpy.var.html), while  `pandas` \n",
    "assumes a `ddof` of \n",
    "[one](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.var.html) ([Bessel's Correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)).\n",
    "\n",
    "Without explicit instructions, these two common libraries will return different results for the '_same_' calculation,\n",
    "so it is important not to inter-mix the libraries. If you should decide to build your own functions involving \n",
    "variance, it will matter how you calculate that value: \n",
    "```python\n",
    "df['obs'].var()  # using pandas\n",
    "```\n",
    "will yield a **different** result than\n",
    "```python\n",
    "np.var(df['obs']) # using numpy\n",
    "```\n",
    "The key (in either case) is to **explicitly** define the `ddof`: \n",
    "```python\n",
    "df['obs'].var(ddof=0)\n",
    "# or\n",
    "np.var(df['obs'], ddof=0)\n",
    "```\n",
    "The original codespec for this benchmark series used numpy, with its default DDOF of 0. We \n",
    "conform to that as canon, with explicit definition of DDOF to ensure compatibility with similar metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio of Standard Deviations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rSD(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    ratio of standard deviation  -- standard deviation of simulated/modeled\n",
    "    values divided by the standard deviation of observed values\n",
    "\n",
    "    Returns:\n",
    "        float: calculated ratio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.std(sim) / np.std(obs)\n",
    "    except ZeroDivisionError:\n",
    "        logging.warning(\"std dev of observed is zero; ratio undefined\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficients: Pearson and Spearman\n",
    "These standard measures are available in reliable and fast libraries from [SciPy](https://scipy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def pearson_r(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Pearson Correlation -- Pearson's R, calculated using the scipi library method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Pearson's R\n",
    "    \"\"\"\n",
    "    return pearsonr(obs, sim)[0]\n",
    "\n",
    "def spearman_r(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Spearman Correlation == Spearman's R, calcuated using the scipy method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Calculated R                                 |\n",
    "    \"\"\"\n",
    "    return spearmanr(obs, sim)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kling-Gupta efficiency (KGE) \n",
    "Gupta, H. V., Kling, H., Yilmaz, K. K., & Martinez, G. F. (2009).  Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling. Journal of hydrology, 377(1-2), 80-91. https://www.sciencedirect.com/science/article/pii/S0022169409004843 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KGE(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    Kling-Gupta efficiency (KGE)\n",
    "\n",
    "    Returns:\n",
    "        float: Calculated KGE\n",
    "    \"\"\"\n",
    "    r = pearsonr(obs, sim)[0]\n",
    "    alpha = rSD(obs, sim)\n",
    "    beta = np.sum(sim) / np.sum(obs)\n",
    "    return 1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logNSE\n",
    "\n",
    "Oudin, L., Andréassian, V., Mathevet, T., Perrin, C., & Michel, C. (2006). Dynamic averaging of rainfall‐runoff model simulations from complementary model parameterizations. Water Resources  Research, 42(7).\n",
    "\n",
    "This is a NSE metric, run against log-transformed data.  Because we can't have log work on zero values, the data must be sanitized to ensure only positive values are passed to `np.log()`. Of the various ways to treat zeros, we use a clipping function to 'promote' values below a small threshold up to that threshold value.  By default, any value below 0.01 is treated as 0.01 for purposes of the log transform. \n",
    "\n",
    "This data sanitization is handled differently within other libraries, notably `hydroeval`.  That package uses a slightly more complex strategy to ensure that `log()` gets clean data to work on. The `hydroeval` developer \n",
    "references [Pushpalatha et al. (2012)](https://doi.org/10.1016/j.jhydrol.2011.11.055) regarding their strategy.  The details of that method are beyond scope here -- just know that if you compare results with `hydroeval`, this metric may yield very slightly different results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logXform(a, **kwargs):\n",
    "    ### we are allowing for the possible future addition of other methods to treat zero values. 'clip' is the default. \n",
    "    if 'clip' in kwargs:\n",
    "        assert kwargs['clip'] > 0\n",
    "        A = a.clip(kwargs['clip'])\n",
    "    return np.log(A)\n",
    "\n",
    "def logNSE(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    logNSE - computes NSE using the log of data (rather than data)\n",
    "\n",
    "        float: Calculated NSE of log(data)\n",
    "    \"\"\"\n",
    "    return NSE(logXform(obs, clip=0.01), logXform(sim, clip=0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Bias\n",
    "\n",
    "A measure of the mean tendency of simulated values to be greater or less than associated observed values, units of percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pbias(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    percent bias -- a measure of the mean tendency of simulated values to be\n",
    "    greater than or less than associated observed values.\n",
    "\n",
    "    Returns:\n",
    "        float: calculated percent bias / units = percent (i.e. 90 rather than 0.90)\n",
    "    \"\"\"\n",
    "    return 100 * np.sum(sim - obs) / np.sum(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special Note on pbias** -- as relates to `hydroeval` and other libraries.\n",
    "* The result we compute here mimics the behavior of the `hydroGOF` R package, and is the result of the code provided in \n",
    "the [model notebook](https://github.com/USGS-python/hytest-evaluation-workflows/blob/main/gallery/streamflow/02_nwm_benchmark_analysis.ipynb) \n",
    "mentioned above. \n",
    "* This differs from the `hydroeval` Python package in an important way.  \n",
    "* `hydroGOF` (and this benchmark) returns:  <br> $100 × \\frac{\\displaystyle\\sum_{i=1}^{n}(\\hat{x}_{i} - x_{i})}{\\displaystyle\\sum_{i=1}^{n}x_{i}}$ <br>where $x$ is 'observed' and $\\hat{x}$ is 'modeled'\n",
    "\n",
    "* `hydroeval` on the other hand, returns:  <br> $100 × \\frac{\\displaystyle\\sum_{i=1}^{n}(x_{i} - \\hat{x}_{i})}{\\displaystyle\\sum_{i=1}^{n}x_{i}}$<br>Note\n",
    "  tht the numerator has switched the ordering of $x$ and $\\hat{x}$. \n",
    "\n",
    "The end result is that these two libraries return values of different sign. `hydroGOF` returns a positive value if the 'modeled' tends to be higher than 'observed', while `hydroeval` will return a negative number in this case. The absolute values of these calulations are the same. \n",
    "\n",
    "The developer for `hydroeval` points to [this document](https://elibrary.asabe.org/abstract.asp?aid=23153) as the source of the math used in that package. \n",
    "\n",
    "This code library uses the same ordering as `hydroGOF`, which is describe in EQN A1 of Yilmaz et al. (2008)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FDC - Flow Duration Curves\n",
    "| Metric | Reference |\n",
    "| ----- | ----- |\n",
    "| percent bias in midsegment slope of the flow-duration curve (FDC) between Q20-Q70 | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC low-segment volume (Q0-Q30) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC high-segment volume (Q98-Q100) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pBiasFMS\n",
    "This is the percent bias of the **slope** of the FDC in the mid-segment part of the curve. See equation A2 of Yilmaz\n",
    "\n",
    "$\\%BiasFMS = 100 × \\cfrac{ [log(QS_{m1}) - log(QS_{m2})] - [log(QO_{m1}) - log(QO_{m2})] }\n",
    "                         { [log(QO_{m1}) - log(QO_{m2})] }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pBiasFMS(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    calculates percent bias of the slope the mid-segment of FDC.\n",
    "\n",
    "    Returns:\n",
    "        float: percent bias for values in exceedence probability range 0.2-0.7\n",
    "    \"\"\"\n",
    "    # Exceedence = 1 - percentile  ;  percentile = 1 - exceedence\n",
    "    # mid-segment slope is defined as those observations with flow exceedence probabilities between 20% and 70%.\n",
    "    # This leads to percentiles/quantiles of 30% and 80% to establish the cut-offs\n",
    "    QO_m1, QO_m2 = np.quantile(obs, [0.30, 0.80])\n",
    "    QS_m1, QS_m2 = np.quantile(sim, [0.30, 0.80])\n",
    "    m = np.log(QS_m1) - np.log(QS_m2)\n",
    "    o = np.log(QO_m1) - np.log(QO_m2)\n",
    "    return 100 * (m - o ) / o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pBiasFLV\n",
    "Percent bias in low-flow segment **volume**.  Note that in low flow segment, a log transform is used to \n",
    "increase sensitivity to very low flows. See equation A4 from Yilmaz.\n",
    "\n",
    "$\\%BiasFHV = -100 × \\cfrac{\n",
    "    \\displaystyle\\sum_{l=1}^L[log(QS_l) - log(QS_L)] - \n",
    "    \\displaystyle\\sum_{l=1}^L[log(QO_l) - log(QO_l)]\n",
    "    }{\n",
    "        \\displaystyle\\sum_{l=1}^L[log(QO_l) - log(QO_L)]\n",
    "    }$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pBiasFLV(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    calculates percent bias over the low-flow segment volume.\n",
    "    Note that for low-flow observations a log transform is done before the\n",
    "    pbias calculation.\n",
    "\n",
    "    Returns:\n",
    "        float: percent bias for values in exceedence probability range 0.7-1.0\n",
    "    \"\"\"\n",
    "    # Exceedence = 1 - percentile  ;  percentile = 1 - exceedence\n",
    "    # Low-Volume is defined as those observations with flow exceedence probabilities between 70% and 100%.\n",
    "    # This leads to percentiles/quantiles of 0% and 30% to establish the cut-offs\n",
    "    _, QO_L = np.quantile(obs, [0.0, 0.30])\n",
    "    _, QS_L = np.quantile(sim, [0.0, 0.30])\n",
    "    idx = (obs <= QO_L) # defines boolean selector index\n",
    "    QS_l = sim[idx]\n",
    "    QO_l = obs[idx]\n",
    "    m = np.sum(np.log(QS_l) - np.log(QS_L))\n",
    "    o = np.sum(np.log(QO_l) - np.log(QO_L))\n",
    "    return -100 * (( m - o ) / o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pBiasFHV\n",
    "Percent bias in high-flow segment **volume**.  See equation A3 of Yilmaz\n",
    "\n",
    "$100 × \\cfrac{\n",
    "    \\displaystyle\\sum_{h=1}^H(QS_h - QO_h)\n",
    "    }{\n",
    "    \\displaystyle\\sum_{h=1}^H QO_h\n",
    "    }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pBiasFHV(obs, sim) -> float:\n",
    "    \"\"\"\n",
    "    calculates percent bias over the high-flow segment volume.\n",
    "\n",
    "    Returns:\n",
    "        float:\n",
    "    \"\"\"\n",
    "    # Exceedence = 1 - percentile  ; percentile = 1 - exceedence\n",
    "    # 'High-Volume' is defined as those observations with flow exceedence probabilities between 0 and 2%.\n",
    "    # This leads to percentiles/quantiles of 98% and 100% to establish the cut-offs\n",
    "    #\n",
    "    minval, maxval = np.quantile(obs, [0.98, 1.0])\n",
    "    idx = (obs >= minval) & (obs <= maxval)\n",
    "    QS_h = sim[idx]\n",
    "    QO_h = obs[idx]\n",
    "    # standard pbias over these observations\n",
    "    return 100 * ( (QS_h - QO_h).sum() / QO_h.sum() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('hytest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7ebce313f85fb1ac8949e834c83f371584cb2422d845bf1570c1220fdedc716"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
