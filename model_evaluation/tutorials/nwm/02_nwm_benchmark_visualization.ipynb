{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23cabac-5a21-48d0-b7b1-e36671f0a718",
   "metadata": {},
   "source": [
    "# \n",
    "# HyTEST hydrologic model benchmark assessment: visualization\n",
    "\n",
    "**Last Update, June 2022**\n",
    "\n",
    "This notebook is an example of how a HyTEST user may examine streamflow benchmark results from a hydrologic model. Here, we are viewing daily streamflow benchmark results from the [National Water Model Retrospective version 2.1](https://registry.opendata.aws/nwm-archive/), forced with AORC, at streamflow benchmark locations (version 1), \"cobalt gages\" ([Foks et al., 2022](https://www.sciencebase.gov/catalog/item/6181ac65d34e9f2789e44897)).\n",
    "\n",
    "Two benchmark results are examined, the standard statistical suite results ([Towler et al., 2022](https://www.sciencebase.gov/catalog/item/62336af9d34ec9f19eeb48fd)) and the decomposition statistical suite (d-score; [Hodson et al., 2022](https://www.sciencebase.gov/catalog/item/61d4c9e9d34ed79293fe91b4))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df078209-e4e8-4429-82b4-8ac491a36686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to beginning, ensure that following Python librariers are installed and loaded\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import panel as pn\n",
    "from geoviews import tile_sources as gvts\n",
    "import intake\n",
    "import param\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ee59d-d7dc-4d7b-9744-3f1fbf6009db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import daily streamflow benchmark results from intake catalog\n",
    "## feel free to try the below code on HPC or cloud resources to view datasets avaliable on the intake catalog\n",
    "#url = 'https://raw.githubusercontent.com/USGS-python/hytest-catalogs/main/hytest_intake_catalog.yml'\n",
    "#cat = intake.open_catalog(url)\n",
    "#list(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283fa19-712c-4312-baa2-cacdcd0d540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the following datasets from github since this has not been updated for the intake catalog. This is not ideal as data gets larger and users start to clone the repo.\n",
    "\n",
    "# streamflow site list (Cobalt gages)\n",
    "df0 = pd.read_csv('https://raw.githubusercontent.com/USGS-python/hytest-evaluation-workflows/main/misc/streamflow_gages_v1_n5390.csv', dtype={'site_no': str})\n",
    "\n",
    "#daily streamflow benchmark results for NWM v2.1 - the standard suite of metrics v1.0\n",
    "df1 = pd.read_csv('https://raw.githubusercontent.com/USGS-python/hytest-evaluation-workflows/main/misc/standard_suite_v1_nwmv2d1.csv', dtype={'site_no': str})\n",
    "\n",
    "#daily streamflow benchmark results for NWM v2.1 - the decomposition suite v0.1\n",
    "df2 = pd.read_csv('https://raw.githubusercontent.com/USGS-python/hytest-evaluation-workflows/main/misc/streamflow_nwm_v2.1-dscore_v0.1-benchmark_v1.csv', dtype={'site_no': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25d7f9-ac59-4de5-8995-6db0e45b317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename lat, lon for plotting\n",
    "df0 = df0.rename(columns={'dec_lat_va':'Lat', 'dec_long_va':'Lon'} )\n",
    "\n",
    "## merge site location information with benchmark results\n",
    "df1 = pd.merge(df1, df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dda23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Benchmark results over the spatial extent of the conterminous United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c5d5a-ebe2-4da5-8d82-4584d40d828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df1 is presented here, and specific columns are called out. If wanting to modify, please see code below.\n",
    "## define which columns are metrics in the widget\n",
    "var_select = pn.widgets.Select(name='Metric', options=list(df1.columns[1:-15]), \n",
    "                               value='pearson_r')\n",
    "\n",
    "base_map_select = pn.widgets.Select(name='Basemap:', \n",
    "                                    options=list(gvts.tile_sources.keys()), \n",
    "                                    value='OSM')\n",
    "\n",
    "@pn.depends(var_select, base_map_select)\n",
    "\n",
    "def plot(var, base_map):\n",
    "    return df1.hvplot.points(x='Lon', y='Lat', color=var, cmap='turbo_r', geo=True, tiles=base_map)\n",
    "\n",
    "col = pn.Column(var_select, base_map_select, plot)\n",
    "col.servable('Hydro Assessment Tool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499da94b-8c8b-48a4-85e7-1fd1f1995070",
   "metadata": {},
   "source": [
    "## Summary of benchmark statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b17d8-a1e2-4290-9ed8-2add0e061d34",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boxplots GAGES-II classification, HUC02 group, or aggregated ecoregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7db9b8-9adc-4f76-bf1a-5067fbe56856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which columns are metrics in the widget and which ones are groups\n",
    "var_select = pn.widgets.Select(name='Metric', options=list(df1.columns[1:-15]), \n",
    "                               value='r')\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "                                    options=list(df1.columns[20:-6]), \n",
    "                                    value='aggecoregion')\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "\n",
    "def plot(var, group):\n",
    "    return df1.hvplot.box(y = var, by = group, height=400, width=800, legend=False)\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('boxplots')\n",
    "\n",
    "## Future additions: \n",
    "## Hover over box to tell user exactly the number of samples in group (count), median, mean, max, min, and IQR.\n",
    "## Add: different states, shapefile user-upload, HLRs, west vs east conus, IWS basins (and subbasins)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4be5e-85b2-4af1-a18d-beadd727f1c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histograms by GAGES-II classification, HUC02 group, or aggregated ecoregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e7e2d-ccd7-4ea7-9689-9d4516932fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which columns are metrics in the widget and which ones are groups\n",
    "var_select = pn.widgets.Select(name='Metric', options=list(df1.columns[1:-15]), \n",
    "                               value='r')\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "                                    options=list(df1.columns[20:-6]), \n",
    "                                    value='aggecoregion')\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "\n",
    "def plot(var, group):\n",
    "    return df1.hvplot.hist(var, group, subplots=True, width=400, bins = 500, legend='top')\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('histograms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5a0a3-a779-4c38-afc8-fb2e806e2e14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metric by Latitude & Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e460ca4-f06d-4e29-a2b8-bfe312400f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which columns are metrics in the widget and which ones are groups\n",
    "var_select = pn.widgets.Select(name='Metric', options=list(df1.columns[1:-15]), \n",
    "                               value='r')\n",
    "\n",
    "group_select = pn.widgets.Select(name='Group By:', \n",
    "                                    options=list(df1.columns[14:16]), \n",
    "                                    value='Lon')\n",
    "\n",
    "@pn.depends(var_select, group_select)\n",
    "\n",
    "def plot(var, group):\n",
    "    return df1.hvplot.scatter(x=group, y=var, height=400, width = 500, legend='top', hover_cols=[\"site_no\",\"Lat\",\"Lon\"])\n",
    "\n",
    "col = pn.Column(var_select, group_select, plot)\n",
    "col.servable('scatter1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fbbcde-f929-4043-a515-d8fe3cbe037f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metric v. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ef2d7-d432-4dc5-9ee3-670ceade3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which columns are metrics in the widget and which ones are groups\n",
    "var_select = pn.widgets.Select(name='Metric', options=list(df1.columns[1:-15]), \n",
    "                               value='r')\n",
    "\n",
    "var2_select = pn.widgets.Select(name='Metric:', \n",
    "                                    options=list(df1.columns[1:-15]), \n",
    "                                    value='rSpearman')\n",
    "\n",
    "@pn.depends(var_select, var2_select)\n",
    "\n",
    "def plot(var, var2):\n",
    "    return df1.hvplot.scatter(x = var, y = var2, height=400, width = 500, legend='top', hover_cols=['site_no','Lat', 'Lon'])\n",
    "\n",
    "col = pn.Column(var_select, var2_select, plot)\n",
    "col.servable('scatter2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0a5d1-0028-4fd8-8732-54ca292876ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Browse Table of Raw Statistics\n",
    "\n",
    "### Standard statistical suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be601d6-e2cc-4d4e-9949-1502ba23d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrollable table with filtering mechanisms\n",
    "df1.hvplot.table(columns=['site_no', 'drain_sqkm','KGE', 'NSE','logNSE','r','rSpearman','rSD','PBIAS','pbiasfdc','PBIAS_HF','PBIAS_LF','complete_yrs','n_days'], sortable=True, selectable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca4f6c-0fa9-4583-a2ea-bd46bdd0636b",
   "metadata": {},
   "source": [
    "### Decomposition statistical suite (d-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17f373-3e82-491a-8fed-017da9d45898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrollable table with filtering mechanisms\n",
    "df2 = pd.merge(df2, df0)\n",
    "df2.hvplot.table(columns=['site_no', 'drain_sqkm','overall','trend','seasonality','variability','bias','distribution','sequence','winter','spring','summer','fall','low','below_avg','above_avg','high','complete_yrs','n_days'], sortable=True, selectable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bac6d-c8ea-4b7d-8939-779f2d072c74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "Foks, S.S., Towler, E., Hodson, T.O., Bock, A.R., Dickinson, J.E., Dugger, A.L., Dunne, K.A., Essaid, H.I., Miles, K.A., Over, T.M., Penn, C.A., Russell, A.M., Saxe, S.W., and Simeone, C.E., 2022, Streamflow benchmark locations for conterminous United States (cobalt gages): U.S. Geological Survey data release, https://doi.org/10.5066/P972P42Z\n",
    "\n",
    "Towler, E., Foks, S.S., Dickinson, J.E., Dugger, A.L., Essaid, H.I., Gochis, D., Hodson, T.O., Viger, R.J., and Zhang, Y., 2022, Daily streamflow performance benchmark defined by the standard statistical suite (v1.0) for the National Water Model Retrospective (v2.1) at benchmark streamflow locations: U.S. Geological Survey data release, https://doi.org/10.5066/P9QT1KV7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9513b1-d2c6-4fc2-9d20-7d6e540b55c7",
   "metadata": {},
   "source": [
    "## *coming soon* - Benchmark results scorecard\n",
    "The scorecard features the results of the decomposition statistical suite, 'd-score'. Cooler colors represent smaller relative error between the model and the evaluation data, whereas warmer colors represent larger error ([Hodson et al., 2021](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021MS002681)). The dscore is ideal when examining or comparing the performance of two or more hydrologic models, though running dscore for one hydrologic model can tell us how much errors are associated with different components within a decomposition. \n",
    "\n",
    "#### References:\n",
    "\n",
    "Hodson, T.O., Foks, S.S., Dugger, A.L., Dunne, K.A., Miles, K.A., Over, T.M., Penn, C.A., Saxe, S.W., Simeone, C.E., Towler, E., and Viger, R.J., 2022, Daily streamflow performance benchmark defined by D-score (v0.1) for the National Water Model (v2.1) at benchmark streamflow locations: U.S. Geological Survey data release, https://doi.org/10.5066/P9MJDNRL\n",
    "\n",
    "Hodson, T.O., Over, T.M. and Foks, S.S., 2021. Mean squared error, deconstructed. Journal of Advances in Modeling Earth Systems, 13(12), p.e2021MS002681, https://doi.org/10.1029/2021MS002681"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
